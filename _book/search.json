[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Epi Methods 2 Review",
    "section": "",
    "text": "1 PH250B\nPHW250B: Epidemiologic Methods II",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>PH250B</span>"
    ]
  },
  {
    "objectID": "chapters/10a_Confounding.html",
    "href": "chapters/10a_Confounding.html",
    "title": "2  Confounding",
    "section": "",
    "text": "The Three “Traditional” Criteria for Confounding\nRandom Association: In small studies or randomized trials, confounding can occur purely due to random chance imbalances, even if the variable isn’t a “true” cause.\nSurrogates: You can control for a variable (like Education) that is a surrogate for a hard-to-measure true confounder (like SES)\nIntermediates: Occasionally, you do control for an intermediate if you are trying to estimate the “Direct Effect” rather than the “Total Effect,” though this requires caution.",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confounding</span>"
    ]
  },
  {
    "objectID": "chapters/10a_Confounding.html#the-three-traditional-criteria-for-confounding",
    "href": "chapters/10a_Confounding.html#the-three-traditional-criteria-for-confounding",
    "title": "2  Confounding",
    "section": "",
    "text": "Association with Exposure: The variable must be associated with the exposure (causally or non-causally) in the source population\nAssociation with Outcome: The variable must be an independent cause or predictor of the disease (outcome) among the unexposed.\nNot an Intermediate: The variable cannot be on the causal pathway between exposure and disease (it cannot be a mediator)",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confounding</span>"
    ]
  },
  {
    "objectID": "chapters/10a_Confounding.html#calculations-identifying-confounding-by-non-collapsibility",
    "href": "chapters/10a_Confounding.html#calculations-identifying-confounding-by-non-collapsibility",
    "title": "2  Confounding",
    "section": "Calculations: Identifying Confounding by “Non-Collapsibility”",
    "text": "Calculations: Identifying Confounding by “Non-Collapsibility”\nThe primary quantitative skill is comparing the Crude measure of association to the Adjusted (or Stratified) measure.\n\nThe Logic:\nIf the association differs “significantly” (magnitude and/or direction) after you stratify or adjust for a variable, that variable is a confounder.\n\n\nThe Check:\n\nCalculate the Crude Estimate (e.g., OR or RR from the total table).\nCalculate the Stratum-Specific Estimates (e.g., OR for males, OR for females)\nCompare: If the stratum-specific estimates are similar to each other (homogeneity) but different from the crude, confounding is present",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confounding</span>"
    ]
  },
  {
    "objectID": "chapters/10a_Confounding.html#classifying-the-direction-of-confounding",
    "href": "chapters/10a_Confounding.html#classifying-the-direction-of-confounding",
    "title": "2  Confounding",
    "section": "Classifying the Direction of Confounding",
    "text": "Classifying the Direction of Confounding\nPositive Confounding: The Crude estimate is further from the null (1.0) than the Adjusted estimate. It overestimates the effect. for example:\n\nTRUE RR: 2.0\nCrude RR: 3.5\n\nNegative Confounding: The Crude estimate is closer to the null (1.0) than the Adjusted estimate. It underestimates the effect\n\nTRUE RR: 2.0\nCrude RR: 1.0\n\nQualitative Confounding: The direction of the association flips (crossover). It changes from harmful to protective or vice versa\n\nTRUE RR: 2.0\nCrude RR: 0.7 (protective)",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confounding</span>"
    ]
  },
  {
    "objectID": "chapters/10a_Confounding.html#using-dags-to-detect-confounding",
    "href": "chapters/10a_Confounding.html#using-dags-to-detect-confounding",
    "title": "2  Confounding",
    "section": "Using DAGs to Detect Confounding",
    "text": "Using DAGs to Detect Confounding\nThe “Backdoor Criterion” is the modern method for identifying confounders. It is often more robust than the traditional 3 criteria\nThe Goal: You want to block all “Backdoor Paths” (paths from Exposure to Outcome that are not the causal path)\n\nHow to select variables for adjustment using a DAG:\nBlock Backdoor Paths: Adjust for variables that close non-causal paths\n(e.g., Common Causes: \\(Exposure \\leftarrow Confounder \\rightarrow Outcome\\))\nAvoid Colliders: Do NOT adjust for a collider\n(a node where two arrowheads meet, like \\(A \\rightarrow Z \\leftarrow B\\)).\nCritical Concept:\nA collider naturally blocks a path. If you adjust for (condition on) a collider, you open the path and introduce selection bias (sometimes called “collider bias”)\nAvoid Descendants: Do not adjust for variables caused by the exposure (descendants).",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confounding</span>"
    ]
  },
  {
    "objectID": "chapters/10a_Confounding.html#collinearity-a-practical-limitation",
    "href": "chapters/10a_Confounding.html#collinearity-a-practical-limitation",
    "title": "2  Confounding",
    "section": "Collinearity (a practical limitation)",
    "text": "Collinearity (a practical limitation)\nBe aware of Collinearity. If a confounder is perfectly correlated with the exposure (e.g., every person with high pollution exposure lives near a freeway, and no one with low pollution lives near a freeway), you cannot adjust for it. There is no variation left in the data to separate the effects (this violates the “positivity” assumption",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Confounding</span>"
    ]
  },
  {
    "objectID": "chapters/10b_Negative_Controls.html",
    "href": "chapters/10b_Negative_Controls.html",
    "title": "3  Negative Controls",
    "section": "",
    "text": "Three Types of Negative Controls\nA negative control is a technique inspired by lab science to detect unanticipated or unmeasured confounding and bias\nThe Core Logic: You set up a comparison where you expect a null result (no association) based on your causal hypothesis.\nThe Test: If you find an association where there shouldn’t be one, it indicates that your study design has bias or confounding\nKey Requirement: The negative control must share the same sources of bias as the primary relationship you are studying. If it has different biases, it won’t be a valid test",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Negative Controls</span>"
    ]
  },
  {
    "objectID": "chapters/10b_Negative_Controls.html#three-types-of-negative-controls",
    "href": "chapters/10b_Negative_Controls.html#three-types-of-negative-controls",
    "title": "3  Negative Controls",
    "section": "",
    "text": "1 - Negative Control Outcome\nDefinition: An outcome that is NOT causally affected by the exposure of interest but shares the same potential confounders.\nExample: In a study of water/sanitation interventions (Exposure) on Diarrhea (Outcome), a negative control outcome could be bruises/scrapes.\nReasoning: Improved sanitation shouldn’t prevent bruises. If you see an association between the intervention and bruises, it suggests reporter bias (e.g., people in the intervention group generally reporting better health) or selection bias.\n\n\n2 - Negative Control Exposure\nDefinition: An exposure that does NOT cause the outcome of interest but shares similar characteristics or biases with the real exposure.\nExample: In a study of Corticosteroids (Exposure) on Asthma symptoms (Outcome), a negative control exposure could be a very low dose of the drug.\nReasoning: The low dose is biologically too weak to help asthma. If symptoms improve on the low dose, it suggests recall bias or a placebo effect.\n\n\n3 - Negative Control Time Period\nDefinition: A time period when the exposure cannot causally affect the outcome.\nExample: In a study of Influenza Vaccination (Exposure) on Mortality (Outcome), look at the period after immunization but before flu season.\nReasoning: The vaccine can’t prevent flu death before the flu virus is circulating. If mortality drops in the vaccinated group during this “pre-season,” it suggests the vaccinated group is just healthier overall (healthy worker/vaccinee bias).",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Negative Controls</span>"
    ]
  },
  {
    "objectID": "chapters/10b_Negative_Controls.html#using-dags-to-validate-negative-controls",
    "href": "chapters/10b_Negative_Controls.html#using-dags-to-validate-negative-controls",
    "title": "3  Negative Controls",
    "section": "Using DAGs to Validate Negative Controls",
    "text": "Using DAGs to Validate Negative Controls\nYou must be able to visualize the “ideal structure” of a negative control outcome in a DAG\nThe Structure: The Negative Control Outcome (\\(N\\)) should have the same incoming arrows from confounders (\\(U\\) and \\(L\\)) as the true Outcome (\\(Y\\)), but NO arrow from the Exposure (\\(A\\))\n\\(U \\rightarrow N\\) and \\(L \\rightarrow N\\) (just like \\(U \\rightarrow Y\\) and \\(L \\rightarrow Y\\))\nCrucial Missing Link: \\(A \\rightarrow N\\) does not exist.\nIf asked to draw a DAG for a negative control, ensure \\(N\\) connects to the confounders but not the exposure.",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Negative Controls</span>"
    ]
  },
  {
    "objectID": "chapters/10b_Negative_Controls.html#calculations-interpreting-the-result",
    "href": "chapters/10b_Negative_Controls.html#calculations-interpreting-the-result",
    "title": "3  Negative Controls",
    "section": "Calculations: Interpreting the Result",
    "text": "Calculations: Interpreting the Result\nThe “calculation” here is often just running the same regression analysis you planned for your main study, but swapping variables\nThe “Null” Check: You calculate the Measure of Association (OR, RR, etc.) for the negative control.\nInterpretation:\nNull Result (e.g., RR \\(\\approx\\) 1.0): Good news. It supports the validity of your main study (no obvious bias detected).\nNon-Null Result (e.g., RR \\(\\ne\\) 1.0): Bad news. It suggests bias or confounding is present in your study design1.\n\nLimitations\nBlunt Tool: If the negative control finds bias, it does not tell you what the bias is or how to fix it. It just sounds the alarm.\nHard to Find: For some research questions, it is impossible to find a valid negative control outcome that shares the same confounders but isn’t caused by the exposure",
    "crumbs": [
      "Confounding",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Negative Controls</span>"
    ]
  },
  {
    "objectID": "chapters/11a_EMM.html",
    "href": "chapters/11a_EMM.html",
    "title": "4  Effect Measure Modification",
    "section": "",
    "text": "What is Effect Measure Modification?\nIn this course, we distinguish between three related but distinct concepts often grouped under the term “interaction” It is crucial to use the precise terminology for the exam.\nKey Exam Concept:",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Measure Modification</span>"
    ]
  },
  {
    "objectID": "chapters/11a_EMM.html#what-is-effect-measure-modification",
    "href": "chapters/11a_EMM.html#what-is-effect-measure-modification",
    "title": "4  Effect Measure Modification",
    "section": "",
    "text": "Statistical Interaction: A departure from the underlying form of a statistical model (e.g., deviation from linearity or log-linearity). It depends entirely on the scale (additive vs. multiplicative) used in the model.\nEffect Measure Modification (EMM): Heterogeneity of the effect measure across strata of a third variable. This is the term we use when we observe different estimates of association (e.g., different Odds Ratios) between subgroups.\nBiologic/Causal Interaction: The interdependence of two causal factors in bringing about an outcome. We often assess this using the Additive Scale, as it aligns with the Sufficient Component Cause model and Counterfactual frameworks.\n\n\n\nConfounding is a bias we want to adjust for (remove).\nEffect Modification is a finding we want to report (describe). It means the biological or public health relationship works differently in different groups. Do not adjust for an effect modifier; stratify and report it.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Measure Modification</span>"
    ]
  },
  {
    "objectID": "chapters/11a_EMM.html#types-of-interaction",
    "href": "chapters/11a_EMM.html#types-of-interaction",
    "title": "4  Effect Measure Modification",
    "section": "Types of Interaction",
    "text": "Types of Interaction\n\n1. Synergism (Positive Interaction)\nThe joint effect of two exposures is greater than the sum (or product) of their independent effects.\n\nInterpretation: The presence of both factors amplifies the risk beyond what we expect from adding them up\n\n\n\n2. Antagonism (Negative Interaction)\nThe joint effect of two exposures is less than the sum (or product) of their independent effects.\n\nInterpretation: One factor potentially dampens the effect of the other\n\n\n\n3. Qualitative (Extreme) Interaction\nThe direction of the association changes across strata.\n\nExample: An exposure is a risk factor in one group (\\(RR &gt; 1\\)) but protective in another (\\(RR &lt; 1\\))\nNote: This is distinct from simple quantitative interaction where the magnitude changes but the direction remains the same.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Measure Modification</span>"
    ]
  },
  {
    "objectID": "chapters/11a_EMM.html#calculations-and-assessment-methods",
    "href": "chapters/11a_EMM.html#calculations-and-assessment-methods",
    "title": "4  Effect Measure Modification",
    "section": "Calculations and Assessment Methods",
    "text": "Calculations and Assessment Methods\nWe assess EMM by comparing the Observed Joint Effect to the Expected Joint Effect under the assumption of no interaction (homogeneity)\n\nMethod 1: Visual Inspection (Stratification)\nCompare the stratum-specific measures of association.\n\nIf \\(OR_{stratum 1} \\approx OR_{stratum 2}\\), EMM is likely absent (Homogeneity).\nIf \\(OR_{stratum 1} \\neq OR_{stratum 2}\\), EMM is likely present (Heterogeneity)\n\n\n\nMethod 2: Chi-Square Test for Homogeneity\nThis statistical test evaluates the null hypothesis that the measure of association is homogeneous (the same) across all strata\n\nNull Hypothesis (\\(H_0\\)): \\(OR_1 = OR_2 = ... = OR_k\\)\nAlternative Hypothesis (\\(H_a\\)): At least one stratum-specific OR is different.\nTest Statistic Formula (\\(X^2_{hom}\\)):\n\n\\[ \\chi^2_{hom} = \\sum_{i=1}^{k} w_i (ln(OR_i) - ln(OR_{adjusted}))^2 \\]\n\nWhere \\(w_i\\) is the weight (inverse variance) for stratum \\(i\\).\nDegrees of Freedom (\\(df\\)) = \\(k - 1\\) (where \\(k\\) is the number of strata).\nInterpretation: If \\(p &lt; 0.05\\) (or typically \\(p &lt; 0.20\\) for interaction tests due to low power), we reject the null and conclude EMM is present\n\n\n\nMethod 3: Additive Scale Interaction (The Causal Standard)\nMany epidemiologists argue that additive interaction most closely reflects biological interaction.\nWe assess this by looking at Risk Differences (RD).\n\nGeneral Rule for Additivity\nInteraction is absent if the joint risk difference equals the sum of the individual risk differences:\n\\[ RD_{11} = RD_{10} + RD_{01} \\]\n\n\\(RD_{11}\\): Risk difference when both exposures are present.\n\\(RD_{10}\\): Risk difference when Exposure A is present, B is absent.\n\\(RD_{01}\\): Risk difference when Exposure B is present, A is absent\n\n\n\nRERI (Relative Excess Risk due to Interaction)\nIf you have relative measures (RR or OR) from a regression model but want to assess additive interaction, you calculate RERI.\nFormula: \\[ RERI = RR_{11} - RR_{10} - RR_{01} + 1 \\]\nInterpretation:\n\nRERI &gt; 0: Positive Interaction (Synergy) on the additive scale.\nRERI &lt; 0: Negative Interaction (Antagonism) on the additive scale.\nRERI = 0: No Interaction (Additivity holds)\n\n\n\n\nMethod 4: Multiplicative Scale Interaction\nThis is the default for logistic and log-linear regression models. We assess this by looking at Ratio Measures (RR, OR).\n\nNo Interaction Rule: The joint relative risk equals the product of the individual relative risks. \\[ RR_{11} = RR_{10} \\times RR_{01} \\]\nInterpretation: If the observed joint RR differs from the product of the individual RRs, there is multiplicative interaction.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Measure Modification</span>"
    ]
  },
  {
    "objectID": "chapters/11a_EMM.html#assessment-in-regression-models",
    "href": "chapters/11a_EMM.html#assessment-in-regression-models",
    "title": "4  Effect Measure Modification",
    "section": "Assessment in Regression Models",
    "text": "Assessment in Regression Models\nWhen using multivariable models, interaction is assessed by adding a product term (\\(X_1 \\times X_2\\)).\n\nModel: \\(Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 (X_1 \\cdot X_2)\\)\nCoefficient \\(\\beta_3\\): Estimates the interaction effect.\n\nIf \\(\\beta_3 \\neq 0\\): Interaction is present.\nThe scale of interaction depends on the model:\n\nLinear Regression: Tests Additive Interaction\nLogistic/Log-Linear Regression: Tests Multiplicative Interaction",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Measure Modification</span>"
    ]
  },
  {
    "objectID": "chapters/11a_EMM.html#exam-prep-checklist",
    "href": "chapters/11a_EMM.html#exam-prep-checklist",
    "title": "4  Effect Measure Modification",
    "section": "Exam Prep Checklist",
    "text": "Exam Prep Checklist\nDistinguish concepts: Can you define the difference between statistical interaction (model-dependent) and biological interaction (additive)?\nIdentify the scale: Are you looking at Risk Differences (Additive) or Risk Ratios (Multiplicative)?\nCalculate RERI: Be prepared to calculate RERI given a table of RRs or ORs to test for biological interaction.\nInterpret the Chi-Square: Know that a significant \\(p\\)-value in a homogeneity test means the strata are different (EMM exists).\nIdentify Confounding vs. EMM:\n\nIf stratum-specific estimates are similar to each other but different from the crude \\(\\rightarrow\\)\n\nConfounding.\n\nIf stratum-specific estimates are different from each other \\(\\rightarrow\\) Effect Measure Modification",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Effect Measure Modification</span>"
    ]
  },
  {
    "objectID": "chapters/11b_EMM_component_cause_model.html",
    "href": "chapters/11b_EMM_component_cause_model.html",
    "title": "5  Effect Modification and the Sufficient Component Cause Model",
    "section": "",
    "text": "Overview: The Sufficient Component Cause (SCC) Model\nThe Sufficient Component Cause model, often visualized as “causal pies,” provides a framework for understanding biological or causal interaction.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Effect Modification and the Sufficient Component Cause Model</span>"
    ]
  },
  {
    "objectID": "chapters/11b_EMM_component_cause_model.html#overview-the-sufficient-component-cause-scc-model",
    "href": "chapters/11b_EMM_component_cause_model.html#overview-the-sufficient-component-cause-scc-model",
    "title": "5  Effect Modification and the Sufficient Component Cause Model",
    "section": "",
    "text": "Sufficient Cause: A complete causal mechanism that inevitably produces the disease. It is represented as a full “pie”.\nComponent Cause: An individual slice of the pie. A single factor (e.g., exposure A) is rarely sufficient on its own; it requires other component causes (e.g., genetic susceptibility, other exposures) to complete the pie\nCausal Interaction Definition: In this model, two factors biologically interact if and only if they act together in the same sufficient cause (the same pie) to produce the outcome",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Effect Modification and the Sufficient Component Cause Model</span>"
    ]
  },
  {
    "objectID": "chapters/11b_EMM_component_cause_model.html#assessing-interaction-using-the-scc-model",
    "href": "chapters/11b_EMM_component_cause_model.html#assessing-interaction-using-the-scc-model",
    "title": "5  Effect Modification and the Sufficient Component Cause Model",
    "section": "Assessing Interaction using the SCC Model",
    "text": "Assessing Interaction using the SCC Model\nTo determine if interaction exists, we compare the Observed Joint Effect of two exposures to the Expected Joint Effect derived from their individual effects. The scale we use (Additive vs. Relative) determines whether our statistical assessment aligns with the biological reality of the causal pies.\n\nExample Scenario\nImagine a population of 1,000 people with four distinct causal mechanisms (pies) operating\n\nPie 1 (Type A): Requires Exposure A + Unknown Factor 1 (causes 100 cases).\nPie 2 (Type B): Requires Exposure B + Unknown Factor 2 (causes 50 cases).\nPie 3 (Interaction): Requires Exposure A + Exposure B + Unknown Factor 3 (causes 50 cases).\n\nThis represents biological interaction.\n\nPie 4 (Background): Requires Unknown Factor 4 (causes 100 cases).\n\n\nStep 1: Calculate Prevalence\nWe calculate the disease prevalence under different exposure conditions:\n\nNeither A nor B (Background only): Only Pie 4 operates.\n\nPrevalence = \\(100/1000 = 0.10\\)\n\nA only (No B): Pie 1 and Pie 4 operate.\n\nPrevalence = \\((100 + 100)/1000 = 0.20\\)\n\nB only (No A): Pie 2 and Pie 4 operate.\n\nPrevalence = \\((50 + 100)/1000 = 0.15\\)\n\nBoth A and B: Pie 1, Pie 2, Pie 3, and Pie 4 operate.\n\nPrevalence = \\((100 + 50 + 50 + 100)/1000 = 0.30\\)\n\n\n\n\n\nStep 2: Assess Interaction on the Additive Scale\nWe check if the Risk Differences (RD) add up.\n\nRD for A alone: \\(0.20 - 0.10 = 0.10\\)\nRD for B alone: \\(0.15 - 0.10 = 0.05\\)\nExpected Joint RD: \\(0.10 + 0.05 = 0.15\\)\nObserved Joint RD: \\(0.30 - 0.10 = 0.20\\)\n\nConclusion: The Observed RD (\\(0.20\\)) \\(\\neq\\) Expected RD (\\(0.15\\)).\nEffect modification is present on the additive scale. This correctly identifies the presence of Pie 3 (the biological interaction).\n\n\nStep 3: Assess Interaction on the Relative Scale\nWe check if the Risk Ratios (RR) multiply.\n\nRR for A alone: \\(0.20 / 0.10 = 2.0\\)\nRR for B alone: \\(0.15 / 0.10 = 1.5\\)\nExpected Joint RR: \\(2.0 \\times 1.5 = 3.0\\)\nObserved Joint RR: \\(0.30 / 0.10 = 3.0\\)\n\nConclusion: The Observed RR (\\(3.0\\)) \\(=\\) Expected RR (\\(3.0\\)).\nEffect modification is absent on the relative scale.\nThis fails to identify the presence of Pie 3 (the biological interaction).",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Effect Modification and the Sufficient Component Cause Model</span>"
    ]
  },
  {
    "objectID": "chapters/11b_EMM_component_cause_model.html#what-happens-if-we-remove-the-interaction-pie",
    "href": "chapters/11b_EMM_component_cause_model.html#what-happens-if-we-remove-the-interaction-pie",
    "title": "5  Effect Modification and the Sufficient Component Cause Model",
    "section": "What happens if we remove the Interaction Pie?",
    "text": "What happens if we remove the Interaction Pie?\nIf we remove Pie 3 (the causal interaction) from the population, the prevalence for “Both A and B” drops to 250/1000 (\\(0.25\\))\n\nAdditive Scale: Observed RD (\\(0.15\\)) now equals Expected RD (\\(0.15\\)).\n\nWe correctly conclude no interaction\n\nRelative Scale: Observed RR (\\(2.5\\)) does not equal Expected RR (\\(3.0\\)).\n\nWe incorrectly conclude interaction is present",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Effect Modification and the Sufficient Component Cause Model</span>"
    ]
  },
  {
    "objectID": "chapters/11b_EMM_component_cause_model.html#summary-of-key-points",
    "href": "chapters/11b_EMM_component_cause_model.html#summary-of-key-points",
    "title": "5  Effect Modification and the Sufficient Component Cause Model",
    "section": "Summary of Key Points",
    "text": "Summary of Key Points\n\nBiological Interaction:\n\nCorresponds to the co-presence of component causes in the same sufficient cause (pie)\n\nAdditive Scale: In the SCC model, a departure from additivity (Observed \\(\\neq\\) Expected) implies the presence of causal interactive types (biological interaction)\nRelative Scale: Assessing interaction on the relative scale (multiplicative) does not reliably detect biological interaction; it may indicate interaction when none exists biologically, or miss it when it is present",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Effect Modification and the Sufficient Component Cause Model</span>"
    ]
  },
  {
    "objectID": "chapters/11c_EMM_potential_outcomes.html",
    "href": "chapters/11c_EMM_potential_outcomes.html",
    "title": "6  Effect Modification, the Potential Outcomes Model, and Causal Interaction",
    "section": "",
    "text": "Overview: The “Punchline”\nWhy do epidemiologists often argue that the Additive Scale is the appropriate scale for detecting causal (biological) interaction?",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Effect Modification, the Potential Outcomes Model, and Causal Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11c_EMM_potential_outcomes.html#overview-the-punchline",
    "href": "chapters/11c_EMM_potential_outcomes.html#overview-the-punchline",
    "title": "6  Effect Modification, the Potential Outcomes Model, and Causal Interaction",
    "section": "",
    "text": "Using the Potential Outcomes (Counterfactual) framework, we can demonstrate that departures from additivity (where Observed Joint Effect \\(\\neq\\) Expected Joint Effect) imply the presence of causal interactive types in the population.\nTherefore, finding interaction on the additive scale suggests a true biological or causal interaction between two exposures.\nIn contrast, interaction on the relative (multiplicative) scale does not necessarily imply causal interaction.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Effect Modification, the Potential Outcomes Model, and Causal Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11c_EMM_potential_outcomes.html#counterfactual-types-recap-one-exposure",
    "href": "chapters/11c_EMM_potential_outcomes.html#counterfactual-types-recap-one-exposure",
    "title": "6  Effect Modification, the Potential Outcomes Model, and Causal Interaction",
    "section": "1. Counterfactual “Types” (Recap: One Exposure)",
    "text": "1. Counterfactual “Types” (Recap: One Exposure)\nRecall that for a single binary exposure, there are 4 potential “types” of individuals in a population:\n\nDoomed (Type 1): Gets disease regardless of exposure (\\(Y_{a=1}=1, Y_{a=0}=1\\)).\nCausal (Type 2): Disease caused by exposure (\\(Y_{a=1}=1, Y_{a=0}=0\\)).\nPreventive (Type 3): Exposure prevents disease (\\(Y_{a=1}=0, Y_{a=0}=1\\)).\nImmune (Type 4): Never gets disease (\\(Y_{a=1}=0, Y_{a=0}=0\\)).\n\n\nRisk Ratio (RR): Depends on “Doomed” types (\\(p_1\\)) and “Causal” types (\\(p_2\\)).\nRisk Difference (RD): Only depends on “Causal” (\\(p_2\\)) and “Preventive” (\\(p_3\\)) types (those amenable to intervention).",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Effect Modification, the Potential Outcomes Model, and Causal Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11c_EMM_potential_outcomes.html#counterfactual-types-with-two-exposures",
    "href": "chapters/11c_EMM_potential_outcomes.html#counterfactual-types-with-two-exposures",
    "title": "6  Effect Modification, the Potential Outcomes Model, and Causal Interaction",
    "section": "2. Counterfactual Types with Two Exposures",
    "text": "2. Counterfactual Types with Two Exposures\nWhen we consider two exposures (X and Z), the number of potential types expands to 16.\n\nEach type represents a specific pattern of potential outcomes under the 4 possible exposure combinations (\\(XZ\\): 11, 10, 01, 00).\n10 of these types reflect Causal Interaction (the outcome depends on both exposures).\n6 of these types reflect No Causal Interaction (at least one factor has no effect, or the effect is constant).\n\n\nExamples of Interaction Types\n\nType 8 (Synergism): Gets disease only when both X and Z are present (\\(Y_{11}=1\\), all others=0).\nType 5 (Antagonism/Blocking): Gets disease unless X is absent and Z is present (specific combination blocks disease).",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Effect Modification, the Potential Outcomes Model, and Causal Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11c_EMM_potential_outcomes.html#the-logic-why-additive-interaction-implies-causal-types",
    "href": "chapters/11c_EMM_potential_outcomes.html#the-logic-why-additive-interaction-implies-causal-types",
    "title": "6  Effect Modification, the Potential Outcomes Model, and Causal Interaction",
    "section": "3. The Logic: Why Additive Interaction Implies Causal Types",
    "text": "3. The Logic: Why Additive Interaction Implies Causal Types\nWe can prove this by calculating the Risk Differences (RD) assuming NO interacting types exist in the population. If our observed data contradicts this (i.e., additivity fails), then interacting types must exist.\n\nStep A: Calculate Risks assuming NO Interaction Types\nWe sum the probabilities (\\(p\\)) of the non-interacting types (Types 1, 4, 6, 11, 13, 16) that result in disease for each exposure scenario:\n\n\\(R_{11}\\) (Both present): \\(p_1 + p_4 + p_6\\)\n\\(R_{01}\\) (Z only): \\(p_1 + p_4 + p_{11}\\)\n\\(R_{10}\\) (X only): \\(p_1 + p_6 + p_{13}\\)\n\\(R_{00}\\) (Neither): \\(p_1 + p_{11} + p_{13}\\)\n\n\n\nStep B: Calculate Indvidual Risk Differences\n\nRD for Z alone (\\(RD_{01}\\)): \\(R_{01} - R_{00} = p_4 - p_{13}\\)\nRD for X alone (\\(RD_{10}\\)): \\(R_{10} - R_{00} = p_6 - p_{11}\\)\n\n\n\nStep C: Calculate Joint Risk Difference\n\nRD for Both (\\(RD_{11}\\)): \\(R_{11} - R_{00} = (p_4 + p_6) - (p_{11} + p_{13})\\)\n\n\n\nStep D: The Additivity Check\nIf we sum the individual effects (\\(RD_{01} + RD_{10}\\)):\n\\[ (p_4 - p_{13}) + (p_6 - p_{11}) = p_4 + p_6 - p_{11} - p_{13} \\]\nThis matches the formula for the Joint RD (\\(RD_{11}\\)) exactly!\n\\[ RD_{11} = RD_{01} + RD_{10} \\]\nConclusion: If there are no interacting causal types in the population, the Additive Risk Difference is homogeneous (additive).",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Effect Modification, the Potential Outcomes Model, and Causal Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11c_EMM_potential_outcomes.html#key-takeaways-for-the-exam",
    "href": "chapters/11c_EMM_potential_outcomes.html#key-takeaways-for-the-exam",
    "title": "6  Effect Modification, the Potential Outcomes Model, and Causal Interaction",
    "section": "Key Takeaways for the Exam",
    "text": "Key Takeaways for the Exam\nDeparture from Additivity: If you observe \\(RD_{11} \\neq RD_{01} + RD_{10}\\),\nyou can infer that at least some causal interaction types are present in your population (assuming no confounding/bias).\nRelative Scale Limitation: If you perform the same proof using Risk Ratios (RR),\nyou find that \\(RR_{11} \\neq RR_{10} \\times RR_{01}\\) even when there are no interacting types.\nImplication: You cannot make strong statements about biological interaction based solely on the multiplicative scale.\nAbsence of Evidence: The absence of additive interaction (perfect additivity) does not guarantee the absence of causal types; it is possible for synergistic and antagonistic types to essentially “cancel each other out” in the population averages.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Effect Modification, the Potential Outcomes Model, and Causal Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11d_additive_scale_interaction.html",
    "href": "chapters/11d_additive_scale_interaction.html",
    "title": "7  Detecting Additive Scale Interaction",
    "section": "",
    "text": "Overview: Why Focus on the Additive Scale?\nWhile statistical interaction can be assessed on both additive and relative scales, the additive scale is generally preferred for assessing biologic or causal interaction.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Detecting Additive Scale Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11d_additive_scale_interaction.html#overview-why-focus-on-the-additive-scale",
    "href": "chapters/11d_additive_scale_interaction.html#overview-why-focus-on-the-additive-scale",
    "title": "7  Detecting Additive Scale Interaction",
    "section": "",
    "text": "Causal Link: As discussed in the Potential Outcomes section, departures from additivity (heterogeneity of the Risk Difference) imply the presence of causal interactive types in the population.\nPublic Health Impact: Additive interaction helps identify subgroups where an intervention would have the largest absolute impact (e.g., preventing the most cases).",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Detecting Additive Scale Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11d_additive_scale_interaction.html#basic-assessment-homogeneity-of-the-risk-difference",
    "href": "chapters/11d_additive_scale_interaction.html#basic-assessment-homogeneity-of-the-risk-difference",
    "title": "7  Detecting Additive Scale Interaction",
    "section": "1. Basic Assessment: Homogeneity of the Risk Difference",
    "text": "1. Basic Assessment: Homogeneity of the Risk Difference\nThe most straightforward way to detect additive interaction is to compare the Observed Joint Risk Difference to the Expected Joint Risk Difference (assuming additivity).\n\nFormula for Interaction\nWe can define the amount of interaction as the difference between the observed and expected effects:\n\\[ Interaction_{additive} = RD_{observed} - RD_{expected} \\]\nSubstituting the probabilities (risks) \\(p_{xz}\\) where \\(x\\) is exposure A and \\(z\\) is exposure B:\n\nObserved RD (Both present): \\(p_{11} - p_{00}\\)\nExpected RD (Sum of individual): \\((p_{10} - p_{00}) + (p_{01} - p_{00})\\)\n\nInteraction Formula:\n\\[ (p_{11} - p_{00}) - [(p_{10} - p_{00}) + (p_{01} - p_{00})] \\]\nThis simplifies to:\n\\[ p_{11} - p_{10} - p_{01} + p_{00} \\]\n\n\nInterpretation (For Harmful Exposures)\nAssuming both exposures increase risk:\n\nResult &gt; 0: Positive (Synergistic) Interaction. The combined effect is greater than the sum of individual effects. Public health interventions on one factor will have a larger benefit in the group exposed to the other factor.\nResult = 0: No Interaction. The combined effect equals the sum of individual effects.\nResult &lt; 0: Negative (Antagonistic) Interaction. The combined effect is less than the sum of individual effects.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Detecting Additive Scale Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11d_additive_scale_interaction.html#relative-excess-risk-due-to-interaction-reri",
    "href": "chapters/11d_additive_scale_interaction.html#relative-excess-risk-due-to-interaction-reri",
    "title": "7  Detecting Additive Scale Interaction",
    "section": "2. Relative Excess Risk due to Interaction (RERI)",
    "text": "2. Relative Excess Risk due to Interaction (RERI)\nIn many studies (e.g., Case-Control), we may only have ratio measures like Risk Ratios (RR) or Odds Ratios (OR), not absolute risks. We can still assess additive interaction using RERI.\n\nDerivation\nStart with the additive interaction formula:\n\\[ p_{11} - p_{10} - p_{01} + p_{00} \\]\nDivide the entire formula by the baseline risk (\\(p_{00}\\)):\n\\[ \\frac{p_{11}}{p_{00}} - \\frac{p_{10}}{p_{00}} - \\frac{p_{01}}{p_{00}} + \\frac{p_{00}}{p_{00}} \\]\nThis converts the risks into Risk Ratios (RR):\n\\[ RERI = RR_{11} - RR_{10} - RR_{01} + 1 \\]\n\n\nInterpretation of RERI (Harmful Exposures)\n\nRERI &gt; 0: Positive (Synergistic) interaction on the additive scale.\nRERI = 0: No additive interaction.\nRERI &lt; 0: Negative (Antagonistic) interaction on the additive scale.\n\nNote: For preventive exposures, the signs for interpretation are reversed (e.g., RERI &lt; 0 implies synergy).\n\n\nUsing Odds Ratios (Case-Control Studies)\nIf the outcome is rare, you can substitute Odds Ratios (OR) for Risk Ratios in the formula:\n\\[ RERI \\approx OR_{11} - OR_{10} - OR_{01} + 1 \\]",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Detecting Additive Scale Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/11d_additive_scale_interaction.html#summary-of-key-points",
    "href": "chapters/11d_additive_scale_interaction.html#summary-of-key-points",
    "title": "7  Detecting Additive Scale Interaction",
    "section": "Summary of Key Points",
    "text": "Summary of Key Points\nMethod: We formalize the assessment of interaction by comparing Observed vs. Expected joint effects.\nAdvantage of RERI: It allows you to detect additive scale interaction (which implies biological interaction) even when you are using relative scale measures (RR or OR) from regression models.\nSignificance: Modern software can calculate confidence intervals for RERI to determine if the additive interaction is statistically significant.",
    "crumbs": [
      "Effect Measure Modification",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Detecting Additive Scale Interaction</span>"
    ]
  },
  {
    "objectID": "chapters/12a_Matching.html",
    "href": "chapters/12a_Matching.html",
    "title": "8  Introduction to Matching",
    "section": "",
    "text": "1. Introduction to Matching",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Matching</span>"
    ]
  },
  {
    "objectID": "chapters/12a_Matching.html#introduction-to-matching",
    "href": "chapters/12a_Matching.html#introduction-to-matching",
    "title": "8  Introduction to Matching",
    "section": "",
    "text": "What is Matching?\nMatching is the selection of a reference series (e.g., controls in a case-control study or unexposed in a cohort study) that is nearly identical to the index series with respect to one or more potential confounders.\n\nGoal: To improve the quality of the counterfactual by making study groups more comparable.\n\n\n\nWhy Match?\nBeyond reducing confounding, matching is used to:\n\nIncrease Statistical Efficiency (Precision): Prevents situations where confounder distributions are dramatically different between groups (e.g., all cases are old, all controls are young).\nIncrease Statistical Power: Particularly in small case-control studies, ensuring sufficient controls in important subgroups.\nFeasibility: Practical reasons during enrollment (e.g., selecting the “next birth” as a control in a hospital study).\n\n\n\nTypes of Matching\n\nIndividual (Pair) Matching: Matching specific subjects based on characteristics (e.g., for every 25-year-old male case, find a 25-year-old male control).\nFrequency Matching: Matching the distribution of characteristics (e.g., if 30% of cases are women, ensure 30% of controls are women).\nDistance Matching: Using algorithms (like propensity scores) to find the “closest” match based on multiple variables in multidimensional space.\n\n\n\nMatching in Different Study Designs\n\n\n\n\n\n\n\n\nStudy Design\nMethod\nPurpose/Effect\n\n\n\n\nCohort\nMatch Exposed to Unexposed\nRemoves confounding in the design phase. Analysis does not require special adjustment for the matched factor.\n\n\nCase-Control\nMatch Cases to Controls\nDoes NOT remove confounding (can introduce selection bias). Must use a matched analysis (stratification) to fix this. Primarily done to improve efficiency.\n\n\nTrials\nBlock Randomization\nMatches participants by block (e.g., geography) before randomizing. Increases efficiency.\n\n\n\n\n\nDisadvantages of Matching\n\nCost/Complexity: Can make sampling difficult.\nExclusion: If no match is found for a case, that case might be excluded (reduces N).\nReduced Flexibility: You cannot estimate the association of the matched variable with the outcome (e.g., if you match on age, you can’t study age as a risk factor).\nOvermatching: Improper matching can obscure the effect of interest (discussed in future lectures).",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Matching</span>"
    ]
  },
  {
    "objectID": "chapters/12a_Matching.html#numerical-examples-of-matching",
    "href": "chapters/12a_Matching.html#numerical-examples-of-matching",
    "title": "8  Introduction to Matching",
    "section": "2. Numerical Examples of Matching",
    "text": "2. Numerical Examples of Matching\n\nA. Matching in a Cohort Study\nIn a cohort study, matching manipulates the exposure distribution .\n\nScenario: A crude analysis of a population shows a Risk Ratio (RR) of 33 due to strong confounding by gender (90% of exposed are men, 10% of unexposed are men).\nThe Match: We design the study to select unexposed subjects such that their gender distribution matches the exposed group (e.g., taking a 10% sample of exposed men and ensuring the unexposed sample is also 90% male).\nResult: The new Crude RR becomes 10, which matches the stratum-specific RRs.\nTakeaway: Matching on a confounder in a cohort study removes confounding. You do not need to adjust for the matched variable in the analysis.\n\n\n\nB. Matching in a Case-Control Study\nIn a case-control study, matching manipulates the disease (case/control) distribution.\n\nScenario: We match controls to cases based on gender.\nThe Problem: By forcing the controls to look like the cases regarding gender (a confounder associated with exposure), we inadvertently make the controls look more like the cases regarding the exposure as well. This biases the crude association toward the null.\nResult: A crude analysis of the matched data yields an Odds Ratio (OR) of 5.0, which is biased (lower than the true OR of 10).\nThe Fix: You must stratify (perform a matched analysis) to obtain the correct estimate. When stratified by the matching factor, the OR returns to 10.\nTakeaway: Matching in a case-control study does not remove confounding; it actually introduces a selection bias that must be corrected by stratifying on the matched variable in the analysis.\n\n\n\n“Breaking the Match”\n\nCohort Studies: If you ignore the matching (break the match) in the analysis, the point estimate remains valid, though variance estimates (CIs) may be incorrect.\nCase-Control Studies: If you ignore the matching in the analysis, you will produce a biased estimate. You generally cannot break the match in case-control studies.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Introduction to Matching</span>"
    ]
  },
  {
    "objectID": "chapters/12b_Overmatching.html",
    "href": "chapters/12b_Overmatching.html",
    "title": "9  Overmatching",
    "section": "",
    "text": "Overview: What is Overmatching?\nOvermatching occurs when you match on a variable that is not a confounder. This can lead to increased cost, loss of statistical efficiency, or even the introduction of bias that cannot be fixed in the analysis.\nGoal: Use Directed Acyclic Graphs (DAGs) in the design phase to identify and avoid matching on variables that will cause these problems.\nIssue with overmatching:",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Overmatching</span>"
    ]
  },
  {
    "objectID": "chapters/12b_Overmatching.html#overview-what-is-overmatching",
    "href": "chapters/12b_Overmatching.html#overview-what-is-overmatching",
    "title": "9  Overmatching",
    "section": "",
    "text": "When you match on a variable that’s strongly predictive of exposure (but not a confounder):\nyou’re making the exposure almost deterministic within your matched sets.\nThat means:\n\nThere’s less variation in exposure among your matched subjects,\nWhich means less ability to detect a difference in outcomes by exposure status,\nEven if the exposure truly causes the outcome!\n\n\nWhen you match on a mediator:\nyou’re conditioning on a variable on the causal path from exposure to outcome\nThat means:\n\nyou’re blocking part of the causal effect of the exposure\nyou make the exposure and outcome look artificially unassociated\nnot because there’s no effect, but because you’ve matched away the pathway through which the effect operates\n\nMatching on a predictor of exposure (that isn’t a confounder) reduces exposure variation and hurts identification.\nMatching on a mediator blocks the effect pathway, and also hurts identification.\nBoth lead to underestimating or even missing the true causal effect",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Overmatching</span>"
    ]
  },
  {
    "objectID": "chapters/12b_Overmatching.html#overmatching-that-harms-statistical-efficiency-precision",
    "href": "chapters/12b_Overmatching.html#overmatching-that-harms-statistical-efficiency-precision",
    "title": "9  Overmatching",
    "section": "1. Overmatching that Harms Statistical Efficiency (Precision)",
    "text": "1. Overmatching that Harms Statistical Efficiency (Precision)\nThis type of overmatching reduces the precision of your effect estimate (wider confidence intervals) without reducing bias.\nThe Theory: In a matched analysis, we only learn from discordant pairs (pairs where Case and Control have different exposures)\nRecall the formula: \\(\\text{Matched OR} = b/c\\) (discordant pairs).\nIf you match on a variable that is strongly correlated with the Exposure (but isn’t a confounder), you force the Control to have the same Exposure status as the Case.\nThis minimizes the number of discordant pairs. If \\(b\\) and \\(c\\) drop to near zero, your statistical power vanishes.\n\nthe “Coffee” example:\n\nExposure: Coffee Drinking. Outcome: Bladder Cancer.\nMatching Variable: Consumption of Cream Substitutes (strongly correlated with coffee, but doesn’t cause cancer).\n\nIf you match a Coffee-Drinking Case to a Control who uses Cream Substitutes, that Control is also almost certainly a Coffee Drinker.\n\nResult: You have a Concordant Pair (Both Exposed). You toss it out. You lose data. You wasted time and money finding a control that provided zero statistical information.\n\n\n\nThe DAG Structure\n\nScenario: The matching variable is associated with the Exposure but NOT the Disease (outcome).\nWhy it’s bad: By matching on this variable, you force the controls to look like the cases with regard to the exposure. This reduces the variation in exposure between cases and controls, which is necessary to estimate the effect.\nResult: Loss of information and statistical power. The stratified analysis (required by matching) was unnecessary because the variable wasn’t a confounder.\n\nExample DAG: (No arrow connects the Matching Variable to Disease)",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Overmatching</span>"
    ]
  },
  {
    "objectID": "chapters/12b_Overmatching.html#overmatching-that-harms-validity-accuracy",
    "href": "chapters/12b_Overmatching.html#overmatching-that-harms-validity-accuracy",
    "title": "9  Overmatching",
    "section": "2. Overmatching that Harms Validity (Accuracy)",
    "text": "2. Overmatching that Harms Validity (Accuracy)\nThis is the most dangerous form of overmatching because it introduces bias (selection bias) that generally cannot be corrected in the analysis.\n\nScenario A: Matching on a Collider\n\nDefinition: A variable that is affected by both the Exposure and the Disease (or sharing common causes with both).\nThe DAG: Exposure \\(\\rightarrow\\) Matching Variable \\(\\leftarrow\\) Disease.\nThe Mechanism: Matching conditions on the collider. This opens a “backdoor path” between exposure and disease, creating a spurious association (bias).\n\n\n\n\nScenario B: Matching on an Intermediate\n\nDefinition: A variable that lies on the causal pathway between Exposure and Disease.\nThe DAG: Exposure \\(\\rightarrow\\) Matching Variable \\(\\rightarrow\\) Disease.\nThe Mechanism: By matching on the intermediate, you are essentially holding it constant. This blocks the causal path you are trying to study, biasing the total effect estimate toward the null.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Overmatching</span>"
    ]
  },
  {
    "objectID": "chapters/12b_Overmatching.html#summary-of-dag-guidelines-for-matching",
    "href": "chapters/12b_Overmatching.html#summary-of-dag-guidelines-for-matching",
    "title": "9  Overmatching",
    "section": "Summary of DAG Guidelines for Matching",
    "text": "Summary of DAG Guidelines for Matching\nWhen selecting matching variables, draw your DAG and check the following criteria:\n\n\n\n\n\n\n\n\nDAG Structure\nDecision\nReason\n\n\n\n\nExposure \\(\\leftarrow\\) Match \\(\\rightarrow\\) Disease\nMATCH\nThis is a Confounder. Matching closes the backdoor path and reduces bias.\n\n\nExposure \\(\\leftrightarrow\\) Match (No link to Disease)\nDO NOT MATCH\nReduces statistical efficiency. Unnecessary stratification.\n\n\nExposure \\(\\rightarrow\\) Match \\(\\leftarrow\\) Disease\nDO NOT MATCH\nThis is a Collider. Matching opens a backdoor path and introduces selection bias.\n\n\nExposure \\(\\rightarrow\\) Match \\(\\rightarrow\\) Disease\nDO NOT MATCH\nThis is an Intermediate. Matching blocks the causal effect you are trying to measure.\n\n\n\n\nCritical:\nIf you identify overmatching that harms validity (collider or intermediate) in a study design, note that this bias cannot be fixed in the analysis phase. It must be avoided during the design phase.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Overmatching</span>"
    ]
  },
  {
    "objectID": "chapters/12c_Matched_Analysis.html",
    "href": "chapters/12c_Matched_Analysis.html",
    "title": "10  Analaysis of Matched Data",
    "section": "",
    "text": "Overview: Approaches to Analysis\nThe method of analysis depends on the type of matching used in the study design.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analaysis of Matched Data</span>"
    ]
  },
  {
    "objectID": "chapters/12c_Matched_Analysis.html#overview-approaches-to-analysis",
    "href": "chapters/12c_Matched_Analysis.html#overview-approaches-to-analysis",
    "title": "10  Analaysis of Matched Data",
    "section": "",
    "text": "Frequency Matching: Analyzed using standard stratified analysis methods.\nPair Matching: Requires special methods that account for the dependent nature of the data (pairs).",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analaysis of Matched Data</span>"
    ]
  },
  {
    "objectID": "chapters/12c_Matched_Analysis.html#analyzing-frequency-matched-data",
    "href": "chapters/12c_Matched_Analysis.html#analyzing-frequency-matched-data",
    "title": "10  Analaysis of Matched Data",
    "section": "1. Analyzing Frequency Matched Data",
    "text": "1. Analyzing Frequency Matched Data\nWhen data is frequency matched (e.g., ensuring 50% females in both cases and controls), you use typical stratification methods.\n\nMethod: Stratify by the matching variable (e.g., sex).\nCalculation: Use the standard weighted average formulas (like Mantel-Haenszel) to calculate the adjusted Odds Ratio (OR) or Risk Ratio (RR).\nControl: You must control for the matching factor in the analysis to remove the selection bias introduced by matching (specifically in case-control studies).",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analaysis of Matched Data</span>"
    ]
  },
  {
    "objectID": "chapters/12c_Matched_Analysis.html#analyzing-pair-matched-data",
    "href": "chapters/12c_Matched_Analysis.html#analyzing-pair-matched-data",
    "title": "10  Analaysis of Matched Data",
    "section": "2. Analyzing Pair Matched Data",
    "text": "2. Analyzing Pair Matched Data\nIn pair matching, the unit of analysis is the pair, not the individual. There are only two observations per stratum (one case, one control).\n\nThe Matched-Pair 2x2 Table\nUnlike the standard 2x2 table, this table counts pairs, not individuals.\n\n\n\n\nControl Exposed\nControl Unexposed\n\n\n\n\nCase Exposed\n\\(a\\) (Concordant)\n\\(b\\) (Discordant)\n\n\nCase Unexposed\n\\(c\\) (Discordant)\n\\(d\\) (Concordant)\n\n\n\n\nConcordant Pairs (\\(a, d\\)): Both case and control have the same exposure status. These provide no information about the relationship between exposure and disease.\nDiscordant Pairs (\\(b, c\\)): Case and control have different exposure status. This is where the information lies.\n\n\n\nA. Case-Control Studies: Matched Odds Ratio\nIn a matched case-control study, the Odds Ratio is calculated using only the discordant pairs.\n\\[ OR_{matched} = \\frac{b}{c} \\]\n\n\\(b\\): Pairs where Case is Exposed, Control is Unexposed.\n\\(c\\): Pairs where Case is Unexposed, Control is Exposed.\nIntuition: If exposure causes disease, we expect more pairs where the Case is the one exposed (\\(b\\)) than pairs where the Control is the one exposed (\\(c\\)).\n\n\n\nB. Cohort Studies: Matched Risk Ratio\nIn a matched cohort study, the layout and formula are different because groups are defined by exposure, not outcome.\n\\[ RR_{matched} = \\frac{\\text{Proportion of Exposed with Disease}}{\\text{Proportion of Unexposed with Disease}} \\]\nFormula using pair counts (where \\(A, B, C, D\\) refer to different pair configurations in a cohort layout):\n\\[ RR = \\frac{A + B}{A + C} \\]\n(Note: Refer to the specific lecture slide for the cohort table layout, as it differs from the case-control table).",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analaysis of Matched Data</span>"
    ]
  },
  {
    "objectID": "chapters/12c_Matched_Analysis.html#breaking-the-match",
    "href": "chapters/12c_Matched_Analysis.html#breaking-the-match",
    "title": "10  Analaysis of Matched Data",
    "section": "3. “Breaking the Match”",
    "text": "3. “Breaking the Match”\nWhat happens if you ignore the matching and analyze the data as if it were an unmatched study?\n\nCase-Control Studies\n\nConsequence: Breaking the match produces a biased estimate (usually towards the null).\nRule: Never break the match in a pair-matched case-control study. You must use matched analysis techniques (e.g., conditional logistic regression).\nException: You can convert pair matching to frequency matching (e.g., matching on age) as long as you stratify by that variable in the analysis.\n\n\n\nCohort Studies\n\nConsequence: Breaking the match usually yields a valid point estimate (unbiased) because matching in cohorts removes confounding.\nCaveat: The variance estimates (Confidence Intervals) will be incorrect (usually too wide) because the analysis ignores the correlation between pairs.\nRule: You generally can break the match to get the RR, but matched analysis is preferred for correct precision.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Analaysis of Matched Data</span>"
    ]
  },
  {
    "objectID": "chapters/12d_Screening_Measures.html",
    "href": "chapters/12d_Screening_Measures.html",
    "title": "11  Screening Measures",
    "section": "",
    "text": "Overview: Key Measures\nIn screening and diagnostic testing, we use several measures to evaluate the performance of a test.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Screening Measures</span>"
    ]
  },
  {
    "objectID": "chapters/12d_Screening_Measures.html#overview-key-measures",
    "href": "chapters/12d_Screening_Measures.html#overview-key-measures",
    "title": "11  Screening Measures",
    "section": "",
    "text": "Validity Measures (Fixed properties of the test): Sensitivity, Specificity.\nPredictive Measures (Depend on prevalence): Positive Predictive Value (PPV), Negative Predictive Value (NPV).\nOverall Performance: Diagnostic Accuracy, ROC Curves.\nClinical Utility: Likelihood Ratios.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Screening Measures</span>"
    ]
  },
  {
    "objectID": "chapters/12d_Screening_Measures.html#sensitivity-and-specificity",
    "href": "chapters/12d_Screening_Measures.html#sensitivity-and-specificity",
    "title": "11  Screening Measures",
    "section": "1. Sensitivity and Specificity",
    "text": "1. Sensitivity and Specificity\nThese measures assess how well a test classifies disease status compared to a “gold standard”.\n\nDefinitions & Formulas\n\n\n\n\n\n\n\n\nMeasure\nDefinition\nFormula\n\n\n\n\nSensitivity\nProbability of a True Positive. The proportion of people with the disease who test positive.\n\\(a / (a + c)\\)\n\n\nSpecificity\nProbability of a True Negative. The proportion of people without the disease who test negative.\n\\(d / (b + d)\\)\n\n\n\n(Where \\(a\\)=True Positives, \\(b\\)=False Positives, \\(c\\)=False Negatives, \\(d\\)=True Negatives)\n\n\nThe Trade-off\nWhen a continuous variable (e.g., blood glucose) is used to classify disease, moving the “cut-off” point affects these measures inversely:\n\nIncreasing Sensitivity (lowering the cutoff to catch more cases) \\(\\rightarrow\\) Decreases Specificity (more false positives).\nIncreasing Specificity (raising the cutoff to be more sure) \\(\\rightarrow\\) Decreases Sensitivity (more false negatives).\n\nClinical Decision: You might prioritize sensitivity if missing a case is dangerous (e.g., cervical cancer/Pap smear), accepting more false positives.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Screening Measures</span>"
    ]
  },
  {
    "objectID": "chapters/12d_Screening_Measures.html#predictive-values-ppv-npv",
    "href": "chapters/12d_Screening_Measures.html#predictive-values-ppv-npv",
    "title": "11  Screening Measures",
    "section": "2. Predictive Values (PPV & NPV)",
    "text": "2. Predictive Values (PPV & NPV)\nThese measures answer the clinical question: “Given my test result, how likely is it that I have the disease?”.\n\nDefinitions & Formulas\n\n\n\n\n\n\n\n\nMeasure\nDefinition\nFormula\n\n\n\n\nPPV\nProportion of people with a positive test who actually have the disease.\n\\(a / (a + b)\\)\n\n\nNPV\nProportion of people with a negative test who are actually disease-free.\n\\(d / (c + d)\\)\n\n\n\n\n\nThe Impact of Prevalence\nUnlike sensitivity and specificity, PPV and NPV are affected by disease prevalence.\n\nHigh Prevalence: Increases PPV (more true positives relative to false positives).\nLow Prevalence: Decreases PPV (a positive result is more likely to be a false positive).",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Screening Measures</span>"
    ]
  },
  {
    "objectID": "chapters/12d_Screening_Measures.html#diagnostic-accuracy",
    "href": "chapters/12d_Screening_Measures.html#diagnostic-accuracy",
    "title": "11  Screening Measures",
    "section": "3. Diagnostic Accuracy",
    "text": "3. Diagnostic Accuracy\nThis measures the overall proportion of correct results (both true positives and true negatives).\n\\[ Accuracy = \\frac{a + d}{N} = \\frac{\\text{True Positives} + \\text{True Negatives}}{\\text{Total Population}} \\]",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Screening Measures</span>"
    ]
  },
  {
    "objectID": "chapters/12d_Screening_Measures.html#likelihood-ratios-lr",
    "href": "chapters/12d_Screening_Measures.html#likelihood-ratios-lr",
    "title": "11  Screening Measures",
    "section": "4. Likelihood Ratios (LR)",
    "text": "4. Likelihood Ratios (LR)\nLikelihood ratios combine sensitivity and specificity to tell us how much a test result changes the probability of disease. They connect the Pre-test Probability to the Post-test Probability.\n\nFormulas\n\nPositive Likelihood Ratio (\\(LR+\\)): How much more likely a positive test is in diseased vs. non-diseased.\n\n\\[ LR+ = \\frac{\\text{Sensitivity}}{1 - \\text{Specificity}} \\]\n\nNegative Likelihood Ratio (\\(LR-\\)): How much less likely a negative test is in diseased vs. non-diseased.\n\n\\[ LR- = \\frac{1 - \\text{Sensitivity}}{\\text{Specificity}} \\]\n\n\nCalculation Steps\n\nPre-test Odds = Probability / (1 - Probability)\nPost-test Odds = Pre-test Odds \\(\\times\\) Likelihood Ratio\nPost-test Probability = Post-test Odds / (1 + Post-test Odds)",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Screening Measures</span>"
    ]
  },
  {
    "objectID": "chapters/12d_Screening_Measures.html#roc-curves",
    "href": "chapters/12d_Screening_Measures.html#roc-curves",
    "title": "11  Screening Measures",
    "section": "5. ROC Curves",
    "text": "5. ROC Curves\nThe Receiver Operating Characteristic (ROC) Curve plots Sensitivity (y-axis) against 1 - Specificity (false positive rate, x-axis).\n[Image of ROC Curve]\n\nUses\nVisualize Trade-offs: See how sensitivity and specificity change as you move the cutoff value.\n\nStrict cutoff: Lower left (Low Sensitivity, High Specificity).\nLoose cutoff: Upper right (High Sensitivity, Low Specificity).\n\nCompare Tests: A “better” test has a curve closer to the upper left corner.\nArea Under the Curve (AUC): The larger the AUC, the better the test. An ideal test has AUC=1.0; a worthless test (diagonal line) has AUC=0.5.",
    "crumbs": [
      "Matching",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Screening Measures</span>"
    ]
  },
  {
    "objectID": "chapters/13a_Linear_Regression.html",
    "href": "chapters/13a_Linear_Regression.html",
    "title": "12  Linear Regression",
    "section": "",
    "text": "When to Use Linear Regression\nYou typically choose a linear regression model based on the type of outcome (dependent) variable you have:\nImportant Note: While it is mathematically possible to model risks or rates with linear regression, it is generally avoided because the model can predict impossible values (e.g., risk &lt; 0 or &gt; 1)",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13a_Linear_Regression.html#when-to-use-linear-regression",
    "href": "chapters/13a_Linear_Regression.html#when-to-use-linear-regression",
    "title": "12  Linear Regression",
    "section": "",
    "text": "Outcome Type: Continuous (e.g., height-for-age Z-score, blood pressure, weight).\nMeasure of Association: Mean Difference\nIdentity Function: Identity Link (we model the outcome directly, without transformation).",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13a_Linear_Regression.html#the-bivariable-linear-model",
    "href": "chapters/13a_Linear_Regression.html#the-bivariable-linear-model",
    "title": "12  Linear Regression",
    "section": "The Bivariable Linear Model:",
    "text": "The Bivariable Linear Model:\n\\[E(Y|X=x) = \\beta_0 + \\beta_1x\\]\n\n\\(E(Y|X=x)\\): The expected mean of the outcome \\(Y\\) given exposure \\(X\\)\n\\(\\beta_0\\) (Intercept): The mean of the outcome \\(Y\\) when the exposure \\(X = 0\\) (the unexposed/reference group)\n\\(\\beta_1\\) (Slope): The Mean Difference in the outcome \\(Y\\) for a one-unit change in \\(X\\)\n\n\nInterpretting the Coefficients:\nScenario A: Binary Exposure (e.g., Treatment vs. Control)\nIf \\(X\\) is binary (\\(0 = \\text{Unexposed}\\), \\(1 = \\text{Exposed}\\)):\n\n\\(\\beta_0\\): The mean outcome among the unexposed\n\\(\\beta_1\\): The difference in the mean outcome between the exposed (\\(X=1\\)) and unexposed (\\(X=0\\))\n\nScenario B: Continuous Exposure (e.g., Weight in kg)\nIf \\(X\\) is continuous:\n\n\\(\\beta_1\\): The change in the mean outcome for a one-unit increase in \\(X\\)\n\nNOTE: Sometimes a “one-unit increase” (e.g., 1 gram of weight) is too small to be meaningful.\n\nYou may need to calculate the effect of a larger shift (e.g., 10 units or 1 Standard Deviation).\nTo do this, simply multiply the coefficient by the amount of the shift (e.g., \\(\\beta_1 \\times 10\\))\n\n\n\nCalculating the Mean Difference (the “Plug-In” Method)\nYou should be able to derive the mean difference using the coefficients. The professors emphasize “plugging in” values to prove the interpretation.\n\nStep-by-Step Calculation:\nTo find the Mean Difference comparing Exposed (\\(X=1\\)) to Unexposed (\\(X=0\\)):\n\nWrite the Model: \\(E(Y|X) = \\beta_0 + \\beta_1 X\\)\nCalculate Mean for Exposed (\\(X=1\\)):\n\n* $$\\beta_0 + \\beta_1(1) = \\beta_0 + \\beta_1$$\n\nCalculate Mean for Unexposed (\\(X=0\\))\n\n* $$\\beta_0 + \\beta_1(0) = \\beta_0$$\n\nSubtract (Exposed - Unexposed):\n\n* $$(\\beta_0 + \\beta_1) - (\\beta_0) = \\beta_1$$\nRESULT: The Mean Difference is equal to \\(\\beta_1\\)",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13a_Linear_Regression.html#multivariable-linear-regression-adjusting-for-confounding",
    "href": "chapters/13a_Linear_Regression.html#multivariable-linear-regression-adjusting-for-confounding",
    "title": "12  Linear Regression",
    "section": "Multivariable Linear Regression (Adjusting for Confounding)",
    "text": "Multivariable Linear Regression (Adjusting for Confounding)\nWhen we add more variables (covariates) to adjust for confounding, the interpretation changes slightly.\n\\[E(Y|X, Z) = \\beta_0 + \\beta_1 X + \\beta_2 Z\\]\n(Where \\(X\\) is exposure and \\(Z\\) is a confounder)\n\n\\(\\beta_1\\): The difference in the mean outcome comparing exposed vs. unexposed, holding \\(Z\\) constant (or adjusting for \\(Z\\))\n\\(\\beta_2\\): The difference in the mean outcome comparing levels of \\(Z\\), holding exposure \\(X\\) constant",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13a_Linear_Regression.html#interaction-in-linear-models",
    "href": "chapters/13a_Linear_Regression.html#interaction-in-linear-models",
    "title": "12  Linear Regression",
    "section": "Interaction in Linear Models",
    "text": "Interaction in Linear Models\nIf we suspect interaction (effect modification), we add a product term (interaction term; measure of effect modification) to the model.\n\\[E(Y|X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 (X_1 \\cdot X_2)\\]\n\\(\\beta_3\\) (Interaction Term): This coefficient assesses the presence of interaction\nInterpretation: \\(\\beta_3\\) represents the difference between the observed joint effect of \\(X_1\\) and \\(X_2\\) and the expected joint effect (sum of individual effects)\nScale: Linear regression models assess interaction on the Additive Scale\n\nAssessing Interaction:\n\nIf \\(\\beta_3 &gt; 0\\): Positive interaction (synergy)\nIf \\(\\beta_3 &lt; 0\\): Negative interaction (antagonism)\nIf \\(\\beta_3 = 0\\): No interaction",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13a_Linear_Regression.html#key-take-aways",
    "href": "chapters/13a_Linear_Regression.html#key-take-aways",
    "title": "12  Linear Regression",
    "section": "Key Take-Aways:",
    "text": "Key Take-Aways:\nIndependence: The model assumes data are independent. It assumes NO clustering (e.g., people within households) and NO auto-correlation (repeated measures on the same person over time).\n\nIf clustering exists: You must use Generalized Estimating Equations (GEE) or Mixed Models\n\nLinearity: The model assumes a straight-line relationship between the independent and dependent variables. It assumes a 1-unit increase in X has the same effect on Y regardless of the starting value of X\nExtrapolation: Be cautious when interpreting results outside the range of observed data (e.g., predicting height for a weight of 0 kg)",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13b_Log_Linear_Regression.html",
    "href": "chapters/13b_Log_Linear_Regression.html",
    "title": "13  Log-Linear Regression",
    "section": "",
    "text": "When to Use Log-Linear Regression\nLog-linear regression is a multivariable analysis method used primarily when your outcome variable is a count or a rate (though it can also be used for binary outcomes when estimating risk ratios). It is distinct from linear regression (for continuous outcomes) and logistic regression (for binary outcomes estimating odds ratios).\nYou choose a log-linear model based on your outcome and desired measure of association:\n\\[\\ln(E(Y|X=x)) = \\beta_0 + \\beta_1x\\]\nNote: In this course, “log” always refers to the natural log (\\(\\ln\\))",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Log-Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13b_Log_Linear_Regression.html#when-to-use-log-linear-regression",
    "href": "chapters/13b_Log_Linear_Regression.html#when-to-use-log-linear-regression",
    "title": "13  Log-Linear Regression",
    "section": "",
    "text": "Outcome Type: Binary (yes/no) or Count (e.g., number of cases).\nMeasure of Association: Risk Ratio (RR) or Rate Ratio (RR).\nIndependent Variables: Can be continuous or binary (or categorical).\nLog-Link Function: Log Link (we transform both sides of equation using log transformation).\nAssumption: Data are independent (no clustering or auto-correlation).\n\n\n\nLeft Side: The natural log (\\(\\ln\\)) of the expected value (mean) of the outcome \\(Y\\), given exposure \\(X\\). This uses a log link function.\nRight Side: The linear combination of the intercept (\\(\\beta_0\\)) and the exposure effect (\\(\\beta_1x\\)).",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Log-Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13b_Log_Linear_Regression.html#interpretting-the-coefficients",
    "href": "chapters/13b_Log_Linear_Regression.html#interpretting-the-coefficients",
    "title": "13  Log-Linear Regression",
    "section": "Interpretting the Coefficients:",
    "text": "Interpretting the Coefficients:\nmust translate the \\(\\beta\\) coefficient back into a meaningful epidemiological measure.\n\nFor a Binary Exposure (\\(X=0, 1\\)):\n\n\\(\\beta_1\\) represents the log risk ratio (or log rate ratio)\nTo get the Risk Ratio (RR) or Rate Ratio, you must exponentiate the coefficient:\n\n\\[RR = e^{\\beta_1}\\]\n\nInterpretation: The relative association between the mean outcome when \\(X=1\\) compared to when \\(X=0\\).\n\n\n\nFor a Continuous Exposure:\n\n\\(e^{\\beta_1}\\) represents the relative change in the risk/rate for a one-unit increase in \\(X\\).",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Log-Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13b_Log_Linear_Regression.html#calculating-risk-ratios",
    "href": "chapters/13b_Log_Linear_Regression.html#calculating-risk-ratios",
    "title": "13  Log-Linear Regression",
    "section": "Calculating Risk Ratios",
    "text": "Calculating Risk Ratios\n\nModel for Exposed:\n(\\(X=1\\)): \\(\\ln(E(Y|X=1)) = \\beta_0 + \\beta_1(1)\\)\n\n\nModel for Unexposed\n(\\(X=0\\)): \\(\\ln(E(Y|X=0)) = \\beta_0 + \\beta_1(0) = \\beta_0\\)\n\n\nDifference in Logs (Log Ratio):\n\\[\\ln(E(Y|X=1)) - \\ln(E(Y|X=0)) = (\\beta_0 + \\beta_1) - \\beta_0 = \\beta_1\\]\n\nLastly, Exponentiate:\n\\[\\frac{E(Y|X=1)}{E(Y|X=0)} = e^{\\beta_1} = \\text{Risk Ratio}\\]",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Log-Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13b_Log_Linear_Regression.html#estimating-rates-person-time-offset",
    "href": "chapters/13b_Log_Linear_Regression.html#estimating-rates-person-time-offset",
    "title": "13  Log-Linear Regression",
    "section": "Estimating Rates (Person-Time Offset)",
    "text": "Estimating Rates (Person-Time Offset)\nIf your outcome is a count of events over time (incidence rate), you must account for the person-time at risk. This is done using an offset.\n\\[\\ln\\left(\\frac{E(Y|X=x)}{\\text{Person-time}}\\right) = \\beta_0 + \\beta_1x\\]\nRewritten for Regression:\n\\[\\ln(E(Y|X=x)) = \\ln(\\text{Person-time}) + \\beta_0 + \\beta_1x\\]\n\nREMEMBER: the offset is the natural log of the person-time. It allows the model to estimate an incidence rate ratio\n\n\nTypes of Log-Linear Models\n\nPoisson Regression: Assumes the variance equals the mean. Common for count data.\nNegative Binomial Regression: Used when the variance is larger than the mean (“overdispersion”). Makes less strong assumptions than Poisson.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Log-Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13b_Log_Linear_Regression.html#key-take-aways",
    "href": "chapters/13b_Log_Linear_Regression.html#key-take-aways",
    "title": "13  Log-Linear Regression",
    "section": "Key Take-Aways:",
    "text": "Key Take-Aways:\n\nLog-Linear Regression\n\nOutcome: Binary, Count, or Rate\nLink Function: Log (\\(\\ln\\))\nMeasure of Association: Risk Ratio or Rate Ratio\nCoefficient (\\(\\beta_1\\)): Log(Risk Ratio) or Log(Rate Ratio)\nConversion: Exponentiate (\\(e^{\\beta_1}\\)) to get the Ratio\nKey Assumption: Independence (no clustering/auto-correlation)\n\n\nExample: investigators decide to treat depression and pet ownership as binary variables. They construct the following regression equation to assess the adjusted association between pet ownership and depression:\n\\[\\ln\\left[\\frac{E(Y|X=x)}{1 - E(Y|X=x)}\\right]\\] = (\\(\\beta_0\\)) +\nRecognize that the equation uses the logit link function:\n\nThis represents the natural log of the odds of the outcome (depression).\nTherefore, this is a Logistic Regression model, which is used to estimate Odds Ratios (OR)\n\nThe variable for Pet Ownership is \\(X\\). The regression coefficient associated with pet ownership is \\(B_1\\)\nIn a logistic regression model, the coefficient \\(B_1\\) represents the log odds ratio for the association between the exposure (\\(X\\)) and the outcome (\\(Y\\)), holding other variables (\\(A\\) and \\(W\\)) constant\nCalculation:\nTo obtain the Odds Ratio (OR) for pet ownership, the investigators must exponentiate the coefficient \\(B_1\\).\\[\\text{Odds Ratio} = e^{B_1}\\]\nInterpretation:\nThe value \\(e^{B_1}\\) represents the odds of depression among pet owners (\\(X=1\\)) divided by the odds of depression among non-pet owners (\\(X=0\\)), adjusted for Age and Income\n\n\nImagine the investigators obtained an odds ratio of 0.9 for pet ownership from the above model. Interpret this estimate.\n\nThe odds of depression among pet owners are 0.9 times the odds of depression among non-pet owners, adjusting for age and income\nAlternatively, this can be interpreted as: Pet owners have 10% lower odds of depression compared to those who do not own pets, holding age and income constant (\\(1.0 - 0.9 = 0.10\\) or \\(10\\%\\)).\n\nKey Elements of this Interpretation:\n\nComparison: Comparing the exposed group (\\(X=1\\), pet owners) to the unexposed/reference group (\\(X=0\\), non-pet owners).\nOutcome: The odds of the outcome (\\(Y\\), depression).\nMagnitude/Direction: 0.9 indicates a protective association (less than 1).\nAdjustment: You must state that this estimate accounts for the other variables in the model (\\(A\\) and \\(W\\)).",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Log-Linear Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13c_Logistic_Regression.html",
    "href": "chapters/13c_Logistic_Regression.html",
    "title": "14  Logistic Regression",
    "section": "",
    "text": "Interpretation of Coefficients:\nWhen we have a binary outcome (e.g., disease/no disease) and want to adjust for multiple variables (exposures and confounders), we use Logistic Regression. This model is used to estimate an Odds Ratio (OR).\n\\[\\ln\\left(\\frac{E(Y|X=x)}{1 - E(Y|X=x)}\\right) = \\text{logit}(E(Y|X=x)) = \\beta_0 + \\beta_1 x\\]\n\\(\\beta_1\\) (Coefficient on X): This is the log odds ratio comparing the odds of the outcome when \\(X=1\\) to when \\(X=0\\) (for a binary exposure)\n\\(\\beta_0\\) (Intercept): The log odds of the outcome when all independent variables (\\(X\\)) are 0.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13c_Logistic_Regression.html#calculating-the-odds-ratio",
    "href": "chapters/13c_Logistic_Regression.html#calculating-the-odds-ratio",
    "title": "14  Logistic Regression",
    "section": "Calculating the Odds Ratio:",
    "text": "Calculating the Odds Ratio:\nFor a Binary Exposure (e.g., \\(X=1\\) vs \\(X=0\\)); you simply exponentiate the coefficient\n\\[\\text{OR} = e^{\\beta_1} = \\exp(\\beta_1)\\]\nExample: If your logistic regression output gives a coefficient for “Smoking” of 0.693:\n\\[\\text{OR} = e^{0.693} \\approx 2.0\\]\nInterpretation: Smokers have 2 times the odds of the outcome compared to non-smokers.\nFor a Continuous Exposure (e.g., Blood Pressure):\nThe \\(\\beta\\) represents the log odds ratio for a one-unit increase in \\(X\\).\n\\[\\text{OR} = e^{\\beta_1}\\]\n\nrepresents the multiplicative change in odds for every 1-unit increase in the continuous variable",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13c_Logistic_Regression.html#logistic-regression-for-case-control-studies",
    "href": "chapters/13c_Logistic_Regression.html#logistic-regression-for-case-control-studies",
    "title": "14  Logistic Regression",
    "section": "Logistic Regression for Case-Control Studies",
    "text": "Logistic Regression for Case-Control Studies\nLogistic regression is particularly useful for case-control studies because these studies sample based on disease status (outcome), making risk calculations impossible directly. However, the Odds Ratio calculated from logistic regression is valid\nNote: If the disease is rare, this Odds Ratio approximates the Risk Ratio",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13c_Logistic_Regression.html#assumptions",
    "href": "chapters/13c_Logistic_Regression.html#assumptions",
    "title": "14  Logistic Regression",
    "section": "Assumptions",
    "text": "Assumptions\nJust like linear models, standard logistic regression assumes:\nIndependence: No clustering or auto-correlation (e.g., no repeated measures on the same person or households).\nLinearity in the Logit: For continuous variables, the log odds of the outcome is assumed to change linearly with the variable.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13c_Logistic_Regression.html#summary-of-logistic-regression-models",
    "href": "chapters/13c_Logistic_Regression.html#summary-of-logistic-regression-models",
    "title": "14  Logistic Regression",
    "section": "Summary of Logistic Regression Models:",
    "text": "Summary of Logistic Regression Models:\n\nOutcome: Binary (e.g., Case/Control, Sick/Healthy)\nLink Function: Logit (Log-Odds)\nMeasure of Association: Odds Ratio (OR)\nCalculation: \\(\\text{OR} = e^{\\beta}\\)\nCoefficient (\\(\\beta_1\\)): Log Odds Ratio for a 1-unit change in X\nKey Assumption: Independence of observations",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "chapters/13d_Survival_Data_Models.html",
    "href": "chapters/13d_Survival_Data_Models.html",
    "title": "15  Models for Survival Data",
    "section": "",
    "text": "Identifying Survival Data and The Hazard Function\nWhat is Survival Data?\nIt includes measurements of the time that passed before a person developed a certain disease or condition (the event).\nExamples: Time until death among cancer patients, time until a car accident while using a mobile phone, or time to recovery after surgery.\nThe Concept of “Hazard” (\\(h(t)\\)):\nWe don’t just look at “risk” in the traditional sense here. We look at Hazard, which is the instantaneous potential for a change in disease status per unit of time at time \\(t\\), relative to the size of the candidate (disease-free) population at that specific time \\(t\\)",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Models for Survival Data</span>"
    ]
  },
  {
    "objectID": "chapters/13d_Survival_Data_Models.html#the-cox-proportional-hazards-model",
    "href": "chapters/13d_Survival_Data_Models.html#the-cox-proportional-hazards-model",
    "title": "15  Models for Survival Data",
    "section": "The Cox Proportional Hazards Model",
    "text": "The Cox Proportional Hazards Model\nWhen you have time-to-event data and want to perform a multivariable analysis (adjusting for potential confounders), the standard method is the Cox Proportional Hazards Model\n\\[\\ln(h(t|X=x)) = \\ln(h_0(t)) + cx\\]\n\n\\(\\ln(h(t|X=x))\\): The log of the hazard at time \\(t\\) given exposure \\(x\\)\n\\(\\ln(h_0(t))\\): The log of the baseline hazard (the hazard when the exposure \\(X=0\\))\n\\(c\\): The regression coefficient\n\nNote: This model is unique because the hazard is indexed by time (\\(t\\)), meaning it varies over time",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Models for Survival Data</span>"
    ]
  },
  {
    "objectID": "chapters/13d_Survival_Data_Models.html#calculations-obtaining-the-hazard-ratio-hr",
    "href": "chapters/13d_Survival_Data_Models.html#calculations-obtaining-the-hazard-ratio-hr",
    "title": "15  Models for Survival Data",
    "section": "Calculations: Obtaining the Hazard Ratio (HR)",
    "text": "Calculations: Obtaining the Hazard Ratio (HR)\nFor a Binary Exposure (\\(X\\)):\nThe Coefficient (\\(c\\)): This represents the log hazard ratio comparing the hazard when \\(X=1\\) to when \\(X=0\\)\nThe Hazard Ratio (\\(HR\\)): To get the actual measure of association, you must exponentiate the coefficient.\n\\[HR = e^c\\]\nThis compares the hazard of the event in the exposed group (\\(X=1\\)) to the unexposed group (\\(X=0\\))\nDerivation (How we get there): Using log rules, the difference in log hazards is the log of the ratio:\n\\[\\ln(HR) = \\ln\\left(\\frac{h(t|X=1)}{h(t|X=0)}\\right) = (\\ln(h_0(t)) + c(1)) - (\\ln(h_0(t)) + c(0)) = c\\]\nTherefore:\n\\[\\frac{h(t|X=1)}{h(t|X=0)} = e^c\\]",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Models for Survival Data</span>"
    ]
  },
  {
    "objectID": "chapters/13d_Survival_Data_Models.html#example-calculation",
    "href": "chapters/13d_Survival_Data_Models.html#example-calculation",
    "title": "15  Models for Survival Data",
    "section": "Example Calculation",
    "text": "Example Calculation\nIf a Cox model gives a coefficient (\\(c\\)) for Gender (Males vs. Females) of 1.2569:\nCalculate HR: \\(e^{1.2569} = 3.52\\)\n\nInterpretation: The hazard of the outcome (e.g., coronary heart disease) for males is 3.52 times the hazard for females.\n\nIf a coefficient for Systolic Blood Pressure is 0.0152 (continuous variable):\nCalculate HR: \\(e^{0.0152} = 1.015\\)\n\nInterpretation: For every 1 mmHg increase in blood pressure, the hazard of the outcome increases by a factor of 1.015.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Models for Survival Data</span>"
    ]
  },
  {
    "objectID": "chapters/13d_Survival_Data_Models.html#the-proportional-hazards-assumption",
    "href": "chapters/13d_Survival_Data_Models.html#the-proportional-hazards-assumption",
    "title": "15  Models for Survival Data",
    "section": "The “Proportional Hazards” Assumption",
    "text": "The “Proportional Hazards” Assumption\nThis is the most critical theoretical concept for this model. The model is called “Proportional Hazards” because it assumes the ratio of the hazards is constant across the entire time interval\nVisual Check: If you plot the hazard over time for the exposed and unexposed groups, the curves should have the same shape—essentially parallel, with one shifted higher or lower than the other\nViolation: If the curves cross or have different shapes, the assumption is not valid. This means the relative hazard changes over time\nImplication: The model estimates one single Hazard Ratio for the entire follow-up period. If the assumption is violated, you may need to stratify by time periods to validly estimate the HR",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Models for Survival Data</span>"
    ]
  },
  {
    "objectID": "chapters/13d_Survival_Data_Models.html#cox-proportional-hazards-model",
    "href": "chapters/13d_Survival_Data_Models.html#cox-proportional-hazards-model",
    "title": "15  Models for Survival Data",
    "section": "Cox Proportional Hazards Model:",
    "text": "Cox Proportional Hazards Model:\n\nOutcome: Time-to-event (Survival) data\nMeasure of Association: Hazard Ratio (HR)\nCalculation: \\(\\text{OR} = e^{\\beta}\\)\nInterpretation: \\(e^c\\) (exponentiated coefficient) is the HR. It approximates the Relative Risk (RR) or Odds Ratio (OR) when cumulative risk is small\nKey Assumption: Proportionality: The ratio of hazards is constant over time (curves do not cross). Also assumes no clustering or auto-correlation",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Models for Survival Data</span>"
    ]
  },
  {
    "objectID": "chapters/13e_Matched_Case_Control_Models.html",
    "href": "chapters/13e_Matched_Case_Control_Models.html",
    "title": "16  Models for Matched Case-Control Data",
    "section": "",
    "text": "The Core Concept: Why We Need Special Models\nthe intuition for analyzing matched case-control data is fundamentally different from matched cohort data\nwhile matching in a cohort study removes confounding, matching in a case-control study actually introduces selection bias that must be controlled for in the analysis.\nIf you “break the match” in a case-control study, you will get a biased estimate.\nYou cannot analyze individually matched case-control data using standard logistic regression (unconditional) or simple \\(2 \\times 2\\) tables that ignore the pairing.\nThe Problem: In individual matching (e.g., matching a case to a control by age and neighborhood), each pair represents a unique stratum. If you have 100 pairs, you essentially have 100 strata.\nThe Solution: We use Conditional Logistic Regression. This model is analogous to standard logistic regression but “conditions” on the matching stratum (the pair)",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Models for Matched Case-Control Data</span>"
    ]
  },
  {
    "objectID": "chapters/13e_Matched_Case_Control_Models.html#calculations-the-matched-pairs-odds-ratio",
    "href": "chapters/13e_Matched_Case_Control_Models.html#calculations-the-matched-pairs-odds-ratio",
    "title": "16  Models for Matched Case-Control Data",
    "section": "Calculations: The “Matched Pairs” Odds Ratio",
    "text": "Calculations: The “Matched Pairs” Odds Ratio\nunderstand the manual calculation for a matched pair analysis (bivariable). This is often tested to ensure you understand where the information comes from.\n\\[\\text{Matched Odds Ratio} = \\frac{B}{C}\\]\n\nB: Pairs where Case is Exposed and Control is Unexposed.\nC: Pairs where Case is Unexposed and Control is Exposed.\n\n\\[\\text{Matched Odds Ratio} = \\frac{\\text{Pairs where Case is Exposed and Control is Unexposed}}{\\text{Pairs where Case is Unexposed and Control is Exposed}}\\]\n\n\nConcordant Pairs (A & D): Both case and control have the same exposure status. These provide no information about the relationship between exposure and disease.\nDiscordant Pairs (B & C): The case and control have different exposure statuses. This is where the information lies.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Models for Matched Case-Control Data</span>"
    ]
  },
  {
    "objectID": "chapters/13e_Matched_Case_Control_Models.html#conditional-logistic-regression-the-multivariable-approach",
    "href": "chapters/13e_Matched_Case_Control_Models.html#conditional-logistic-regression-the-multivariable-approach",
    "title": "16  Models for Matched Case-Control Data",
    "section": "Conditional Logistic Regression (The Multivariable Approach)",
    "text": "Conditional Logistic Regression (The Multivariable Approach)\nWhen we move to multivariable analysis, we use Conditional Logistic Regression.\nYou need this when you want to adjust for additional confounders that you did not match on.\n\nWhen to use it:\n\nIndividually matched case-control studies.\nDensity sampling designs (matching on person-time).\nFrequency Matching Exception: If you used frequency matching (e.g., ensuring 20% of cases and 20% of controls are female), you can actually use standard logistic regression as long as you include the matching variables in the model.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Models for Matched Case-Control Data</span>"
    ]
  },
  {
    "objectID": "chapters/13e_Matched_Case_Control_Models.html#interpretation-of-coefficients",
    "href": "chapters/13e_Matched_Case_Control_Models.html#interpretation-of-coefficients",
    "title": "16  Models for Matched Case-Control Data",
    "section": "Interpretation of Coefficients:",
    "text": "Interpretation of Coefficients:\nThe model output looks very similar to standard logistic regression.\n\\(\\beta_1\\) (for a binary exposure \\(X\\)) = The difference in the log odds of the outcome when \\(X=1\\) versus \\(X=0\\)\nOdds Ratio: To get the OR, you simply exponentiate the coefficient\n\\[\\text{OR} = e^{\\beta_1}\\]\nThis estimates the odds ratio adjusting for the matching factors (automatically handled by the design/model) AND any other confounders included in the model.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Models for Matched Case-Control Data</span>"
    ]
  },
  {
    "objectID": "chapters/13e_Matched_Case_Control_Models.html#critical-pitfalls-to-avoid",
    "href": "chapters/13e_Matched_Case_Control_Models.html#critical-pitfalls-to-avoid",
    "title": "16  Models for Matched Case-Control Data",
    "section": "Critical Pitfalls to Avoid",
    "text": "Critical Pitfalls to Avoid\n\nDo NOT Break the Match\nNever analyze matched case-control data as if it were unmatched (unless the population OR is 1.0, which you rarely know). Doing so biases your result toward the null.\n\n\nAssumption of Independence\nLike the other models we have discussed (Linear, Logistic, Poisson), Conditional Logistic Regression generally assumes no clustering or auto-correlation (other than the matching itself).\n\n\nEfficiency vs. Validity\nWhile matching can improve statistical efficiency (precision) by ensuring balanced strata, improperly analyzing it harms validity.",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Models for Matched Case-Control Data</span>"
    ]
  },
  {
    "objectID": "chapters/13e_Matched_Case_Control_Models.html#summary-of-matched-case-control-model",
    "href": "chapters/13e_Matched_Case_Control_Models.html#summary-of-matched-case-control-model",
    "title": "16  Models for Matched Case-Control Data",
    "section": "Summary of Matched Case Control Model",
    "text": "Summary of Matched Case Control Model\nCalculation: \\(OR = \\frac{\\text{Pairs(Case+, Control-)}}{\\text{Pairs(Case-, Control+)}}\\).\nModel: Conditional Logistic Regression\nWhy Model?:\nTo adjust for non-matched confounders (e.g., matching on age/sex, but modeling to adjust for smoking)",
    "crumbs": [
      "Regression",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Models for Matched Case-Control Data</span>"
    ]
  },
  {
    "objectID": "chapters/14a_Propensity_Scores.html",
    "href": "chapters/14a_Propensity_Scores.html",
    "title": "17  Propensity Scores",
    "section": "",
    "text": "Why use propensity score?\nThe predicted probability (“propensity”) of exposure in a particular individual based on a set of characteristics.\nIn simpler terms, it is a single number that summarizes all the covariate information about a person into the likelihood that they would have received the intervention, regardless of whether they actually did.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Propensity Scores</span>"
    ]
  },
  {
    "objectID": "chapters/14a_Propensity_Scores.html#why-use-propensity-score",
    "href": "chapters/14a_Propensity_Scores.html#why-use-propensity-score",
    "title": "17  Propensity Scores",
    "section": "",
    "text": "To handle time-dependent confounding: Standard multivariable models are biased in the presence of time-dependent confounding\nTo mimic randomization in observational studies: This is the primary focus of the lecture. When evaluating an existing intervention where you cannot randomize (e.g., a government vaccination program), propensity scores allow you to identify a comparison group of untreated individuals who are “exchangeable” (very similar) to those who were treated.\n\n\nStudy with time-dependent confounding\n\nadjusting for a time-dependent confounder changes the quantity that we estimate because ti is on the causal path from the exposure to the outcome\nif we don’t adjust for a time-dependent confounder, our estimate will be confounded.\na time-dependent confounder is a variable that:\n\nis affected by prior exposure\npredicts subsequent exposure\nassociated with or causes the outcome\n\n\n\n\nYou want to mimic randomization in an observations study\n\n(often one that evaluates an existing intervention)\nuse propensity scores to identify who can be enrolled as a comparison group, attempting to mimic randomization by finding untreated individuals who are ideally exchangeable with those who were treated.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Propensity Scores</span>"
    ]
  },
  {
    "objectID": "chapters/14a_Propensity_Scores.html#the-4-steps-of-propensity-score-matching",
    "href": "chapters/14a_Propensity_Scores.html#the-4-steps-of-propensity-score-matching",
    "title": "17  Propensity Scores",
    "section": "The 4 Steps of Propensity Score Matching",
    "text": "The 4 Steps of Propensity Score Matching\n\nStep 1: Obtain pre-intervention data You need data on the population before the intervention occurred.\n\nGoal: Obtain data on variables that are potential confounders.\nNote: We use pre-intervention data because if the intervention affects the covariates, they cannot be used as valid factors for selection.\n\n\n\nStep 2: Estimate the probability of treatment\n\nWe model the probability of being treated (\\(A=1\\)) conditional on a set of characteristics (confounders \\(W\\))\nMethod: Typically, logistic regression is used.\nCrucial Distinction: In this step, the “outcome” of your regression model is the exposure/treatment (A), not the health outcome (Y)\nFormula:\n\n\\[\\ln\\left(\\frac{Pr(A|W=w)}{1-Pr(A|W=w)}\\right) = \\beta_{0}+\\beta_{1}W_{1}+\\beta_{2}W_{2}\\]\n\n\nStep 3: Calculate the Propensity Score for each individual\n\nUse the regression model fit to estimate the probability for every individual (or cluster/school) in the dataset.\nCalculation: You plug the individual’s covariates (\\(W\\)) into the model to get a probability between 0 and 1.\nKey Concept: We calculate this probability for everyone, including those who did not receive the treatment\n\n\n\nStep 4: Match treated and untreated individuals\n\nMatch each treated individual with an untreated individual who has a similar propensity score\nThe Result: This identifies a subset of untreated individuals to serve as the control group.\nIntuition: If a treated school had a propensity score of 0.89 and an untreated school had a score of 0.88, they are matched because they had a similar likelihood of receiving the program based on their characteristics",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Propensity Scores</span>"
    ]
  },
  {
    "objectID": "chapters/14a_Propensity_Scores.html#key-concepts",
    "href": "chapters/14a_Propensity_Scores.html#key-concepts",
    "title": "17  Propensity Scores",
    "section": "Key Concepts",
    "text": "Key Concepts\n\n1. Interpretation of Results\nThe interpretation of a measure of association (like Risk Difference) in a propensity score matched study is different from a standard analysis.\n\nTarget Population: It estimates the average association for the treated population (i.e., if all \\(A=1\\) were matched to an \\(A=0\\))\nCounterfactual Notation:\n\nStandard Risk Difference (RD): \\(E[Y_{1}] - E[Y_{0}]\\)\nPropensity Matched RD: \\(E[Y_{1}|A=1] - E[Y_{0}|A=1]\\)\nMeaning: You are estimating the difference in outcomes specifically for the group that received the intervention, rather than the total population.\n\n\n\n\n2. Relationship to Other Methods\nIPTW: Propensity scores are also used in Inverse Probability of Treatment Weighting (IPTW). In IPTW, the propensity score is used to create weights ( \\(1/PS\\) ) for exposed, \\(1/(1-PS)\\) for unexposed) rather than for matching\nStandardization: IPTW (which uses propensity scores) is related to standardization. The weights in IPTW function similarly to population counts in standardization, but IPTW allows adjustment for multiple confounders simultaneously\n\n\n3. Limitations (“Garbage In, Garbage Out”)\nPropensity score matching cannot fix bad data.\n\nIt cannot account for unmeasured confounding\nThe model used to estimate the propensity score must still include confounders that meet the backdoor criterion\n\n\nBackdoor criterion:\nThe backdoor criterion is a graphical rule used in causal inference to determine which variables you must “control for” (or adjust) in a study to separate a true causal effect from misleading correlations.\nIt is based on Directed Acyclic Graphs (DAGs)—visual maps of how variables influence each other. The criterion helps you identify a set of variables that, when held constant, blocks all “backdoor paths” (non-causal paths) between your treatment and your outcome, leaving only the direct causal path open.\nWhy It Matters In observational data, correlation does not equal causation because of confounders—hidden common causes that influence both the treatment and the outcome.\nWithout Backdoor Adjustment: You might think a drug cures a disease, but really, younger people were just more likely to take the drug and also more likely to recover naturally. Age is a “backdoor” allowing a spurious correlation.\nWith Backdoor Adjustment: By applying the criterion, you mathematically simulate a randomized controlled trial (intervention) using observational data.\n\nThe Two Rules of the Backdoor Criterion\nA set of variables (\\(Z\\)) satisfies the backdoor criterion relative to a treatment (\\(X\\)) and outcome (\\(Y\\)) if:\n\n\nNo Descendants: No variable in \\(Z\\) is a descendant of the treatment \\(X\\) (you cannot control for variables that are caused by the treatment, like mediators).\n\n\nBlock All Backdoor Paths: The set \\(Z\\) blocks every path between \\(X\\) and \\(Y\\) that contains an arrow pointing into \\(X\\) (e.g., \\(X \\leftarrow C \\rightarrow Y\\)).\n\n\nSimple Example: Imagine you want to know if Ice Cream Sales (\\(X\\)) cause Crime (\\(Y\\))  …\n\nObservation: Sales and crime both go up at the same time.\nThe Backdoor Path: There is a third variable, Heat (\\(Z\\)). Heat causes people to buy ice cream (\\(Z \\rightarrow X\\)) and heat makes people irritable/aggressive (\\(Z \\rightarrow Y\\)). This creates a path: \\(X \\leftarrow Z \\rightarrow Y\\).\nApplying the Criterion:\n\nIs \\(Z\\) (Heat) caused by \\(X\\) (Ice Cream)? No. (Rule 1 passed).\nDoes conditioning on \\(Z\\) block the path? Yes. If we look only at days with the same temperature, the correlation between ice cream and crime disappears. (Rule 2 passed).\n\nConclusion: By adjusting for Heat, you close the “backdoor” and correctly find zero causal link between ice cream and crime.\n\nBackdoor vs. Frontdoor\nSometimes you cannot close the backdoor because the confounder is unobserved (you didn’t measure it). In those cases, you might use the Frontdoor Criterion, which relies on the mechanism after the treatment (a mediator) rather than common causes before it.\n\nBackdoor: Blocks the common cause (\\(X \\leftarrow C \\rightarrow Y\\)).\nFrontdoor: Uses the intermediate step (\\(X \\rightarrow M \\rightarrow Y\\)) to isolate the effect when \\(C\\) is unknown.",
    "crumbs": [
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Propensity Scores</span>"
    ]
  },
  {
    "objectID": "chapters/14b_Sample_Size_Power.html",
    "href": "chapters/14b_Sample_Size_Power.html",
    "title": "18  Sample Size and Power",
    "section": "",
    "text": "The Big Picture: Why do we calculate sample size?\nIn the planning stage, we face a “Goldilocks” problem:",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Sample Size and Power</span>"
    ]
  },
  {
    "objectID": "chapters/14b_Sample_Size_Power.html#the-big-picture-why-do-we-calculate-sample-size",
    "href": "chapters/14b_Sample_Size_Power.html#the-big-picture-why-do-we-calculate-sample-size",
    "title": "18  Sample Size and Power",
    "section": "",
    "text": "Too Small: You might miss a real difference between groups because your study can’t distinguish the signal from the noise (random variation).\nToo Large: You waste money, time, and expose more participants than necessary to an intervention (ethical concerns).\n\n\nThe “Sample Size Samba”\nRemember that in reality, this is an iterative process (a “samba”) between the scientific ideal and the budget/logistical reality.\nYou calculate, check the budget, adjust the MDE or power, and calculate again\n\n\nThe Goal: We want a sample size just large enough to distinguish a true difference from random variation",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Sample Size and Power</span>"
    ]
  },
  {
    "objectID": "chapters/14b_Sample_Size_Power.html#the-four-pillars-of-power-calculations",
    "href": "chapters/14b_Sample_Size_Power.html#the-four-pillars-of-power-calculations",
    "title": "18  Sample Size and Power",
    "section": "The Four Pillars of Power Calculations",
    "text": "The Four Pillars of Power Calculations\nDefinition of Power: The probability of correctly rejecting the null hypothesis when it is false\n\n1. Hypotheses\nYou must specify what you are testing:\n\nNull Hypothesis (\\(H_0\\)): There is no difference between groups (e.g., Risk Difference = 0).\nAlternative Hypothesis (\\(H_a\\)): There is a difference (e.g., Risk Difference \\(\\neq\\) 0).\n\n\n\n2. Error Rates and Power\nWe deal with two types of errors because we are looking at a sample, not a census.\n\nType 1 Error (alpha - \\(\\alpha\\) ) : The False Positive. Rejecting the null when it is actually true.\n\nStandard: Usually set to 0.05 (5%).\n\nType 2 Error (beta - \\(\\beta\\) ) : The False Negative. Failing to reject the null when it is actually false (missing a real effect).\n\nStandard: We usually aim for Power (\\(1 - \\beta\\)) of 80%\n\n\nIf I decrease my Type I error rate (e.g., from 0.05 to 0.01) what happens to the required sample size?\n\nIt increases. Being more “strict” requires more evidence\n\n\n\n3. Minimum Detectable Effect (MDE)\nThis is the smallest difference between groups that you want to be able to detect.\n\nexample: If the baseline illness rate is 3.4%, do you want to detect a jump to 3.5% (tiny effect) or 4.4% (larger effect)?\nkey concept: Smaller effects are harder to find. To detect a smaller MDE, you need a larger sample size\n\nIf I want to detect a smaller difference (smaller MDE), what happens to sample size?\n\nIt increases. It is harder to find a needle in a haystack than a crowbar.\n\n\n\n4. Variability ( \\(\\sigma\\) or SD )\nHow much “noise” is in your data?\n\nkey concept: The more variable the outcome (higher Standard Deviation), the harder it is to see the signal. Higher variability requires a larger sample size\n\nIf my data is highly variable (high SD), what happens to sample size?\n\nIt increases. You need more data to see through the noise",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Sample Size and Power</span>"
    ]
  },
  {
    "objectID": "chapters/14b_Sample_Size_Power.html#visualizing-power-the-two-curves-concept",
    "href": "chapters/14b_Sample_Size_Power.html#visualizing-power-the-two-curves-concept",
    "title": "18  Sample Size and Power",
    "section": "Visualizing Power (The “Two Curves” Concept)",
    "text": "Visualizing Power (The “Two Curves” Concept)\nvisualize two bell curves: the Null Distribution (centered at 0 effect) and the Alternative Distribution (centered at the effect size you hope to find).\nHow do we increase Power (the area under the Alternative curve)?\n\nIncrease the Effect Size: Move the two curves further apart. It is easier to tell them apart.\nIncrease Sample Size: This shrinks the Standard Error. Visually, this makes the bell curves “skinnier” and taller, so they overlap less.\nIncrease Alpha: Moving the critical value to the left increases power, but increases the risk of a False Positive.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Sample Size and Power</span>"
    ]
  },
  {
    "objectID": "chapters/14b_Sample_Size_Power.html#the-twist-cluster-randomized-trials-crts",
    "href": "chapters/14b_Sample_Size_Power.html#the-twist-cluster-randomized-trials-crts",
    "title": "18  Sample Size and Power",
    "section": "The Twist: Cluster Randomized Trials (CRTs)",
    "text": "The Twist: Cluster Randomized Trials (CRTs)\nThis is a major focus of PHW250B. In many public health interventions (like the Bangladesh WASH study), we randomize villages or compounds, not individuals\n\nThe Problem: Independence In standard statistics, we assume every person is independent.In clusters, people within the same village are more similar to each other (correlated). This correlation provides less information than if they were independent\nThe Solution: The Design Effect (Deff) To calculate sample size for clusters, we calculate the sample size for individuals and then inflate it using the Design Effect\n\n\\[Deff = 1 + (m - 1)\\rho\\]\n\n\\(m\\): Average cluster size (number of people per cluster).\n\\(\\rho\\) (Rho): Intraclass Correlation Coefficient (ICC). A measure of how correlated people are within a cluster\n\nIf \\(\\rho = 0\\): No correlation (same as individual RCT).\nIf \\(\\rho = 1\\): Everyone in the cluster is the same (Effective sample size = number of clusters)\n\n\n\nKey Concept:\nPower in clustered designs is driven primarily by the number of clusters (\\(k\\)), NOT the number of people per cluster (\\(m\\)). Once you reach a certain cluster size (Rule of thumb: \\(m &gt; 1/\\rho\\)), adding more people to the cluster adds very little power\nIn a cluster trial, is it better to double the number of clusters or double the number of people per cluster?\n\nDouble the number of clusters. This adds more power",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Sample Size and Power</span>"
    ]
  },
  {
    "objectID": "chapters/14c_IPTW_G_computation.html",
    "href": "chapters/14c_IPTW_G_computation.html",
    "title": "19  Inverse Probability of Treatment Weighting (IPTW) and G-Computation",
    "section": "",
    "text": "IPTW creates a pseudo-population\nBoth IPTW and G-Computation are modern methods from the causal inference literature used to handle confounding, particularly time-dependent confounding. While multivariable regression is biased in the presence of time-dependent confounding, these methods can provide unbiased estimates if assumptions are met.\nThey both separate the step of adjusting for confounding from the step of estimating the parameter, allowing for the estimation of flexible parameters (like population intervention models)",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Inverse Probability of Treatment Weighting (IPTW) and G-Computation</span>"
    ]
  },
  {
    "objectID": "chapters/14c_IPTW_G_computation.html#inverse-probability-of-treatment-weighting-iptw",
    "href": "chapters/14c_IPTW_G_computation.html#inverse-probability-of-treatment-weighting-iptw",
    "title": "19  Inverse Probability of Treatment Weighting (IPTW) and G-Computation",
    "section": "Inverse Probability of Treatment Weighting (IPTW)",
    "text": "Inverse Probability of Treatment Weighting (IPTW)\nPurpose: IPTW aims to mimic a randomized trial using observational data by creating a “pseudo-population” where the exposure is independent of confounders\n\nconceptually related to standardization\n\nIn standardization, we apply specific population counts (weights) to strata. In IPTW, we use the inverse probability of treatment as the weight to balance the population\n\n\n\nThe Process (Steps):\n\nEstimate the Propensity Score: Calculate the probability of being treated/exposed (\\(A=1\\)) given a set of covariates (\\(W\\)) for each individual, typically using logistic regression\nDefine Weights: Create weights based on the inverse of the propensity score (\\(PS\\))\n\n* Exposed: Weight = $1 / PS$\n\n* Unexposed: Weight = $1 / (1 - PS)$\n\nApply Weights: Apply these weights to the data. This creates a “pseudo-population” where the distribution of confounders is balanced between exposed and unexposed groups\n\n* Visual: Up-weighting underrepresented groups (e.g., older unexposed people) makes the treated and untreated groups look similar\n\nCalculate Measure of Association: Calculate the mean of the outcome in the weighted population. You can calculate Risk Differences (RD) or Risk Ratios (RR) using this weighted data\n\nInterpretation: The result estimates the average association if everyone in the population had the treatment compared to if no one had the treatment",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Inverse Probability of Treatment Weighting (IPTW) and G-Computation</span>"
    ]
  },
  {
    "objectID": "chapters/14c_IPTW_G_computation.html#g-computation",
    "href": "chapters/14c_IPTW_G_computation.html#g-computation",
    "title": "19  Inverse Probability of Treatment Weighting (IPTW) and G-Computation",
    "section": "G-Computation",
    "text": "G-Computation\nPurpose: G-computation estimates the association by using a regression model to predict “counterfactual” outcomes for every individual under different treatment scenarios\n\nThe Process (Steps):\n\nOutcome Regression: Fit a regression model (e.g., logistic, linear) for the outcome (\\(Y\\)) adjusting for exposure (\\(A\\)) and confounders (\\(W\\))\nPredict Counterfactuals: Use the coefficients from that model to predict the outcome for every individual in the dataset under two specific scenarios\n\n* Set exposure to \"Exposed\" ($A=1$) for everyone (regardless of what they actually did).\n\n* Set exposure to \"Unexposed\" ($A=0$) for everyone.\n\nEstimate Marginal Risk: Calculate the mean of these predicted outcomes for the entire population under the “everyone exposed” scenario and the “everyone unexposed” scenario\nCalculate Measure of Association: Compare these means (e.g., divide them for a Risk Ratio or subtract for a Risk Difference)\n\nInterpretation: Like IPTW, the result represents the ratio or difference in the average outcome if everyone had the treatment compared to if no one had the treatment",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Inverse Probability of Treatment Weighting (IPTW) and G-Computation</span>"
    ]
  },
  {
    "objectID": "chapters/15a_Meta_Analysis.html",
    "href": "chapters/15a_Meta_Analysis.html",
    "title": "20  Systematic Review and Meta-analysis",
    "section": "",
    "text": "Systematic Reviews\nA systematic review is a rigorous, reproducible method to identify, evaluate, and synthesize all available evidence on a specific research question. Unlike a narrative review, which is subjective and relies on an expert’s selection of studies, a systematic review follows a strict protocol to minimize bias",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Systematic Review and Meta-analysis</span>"
    ]
  },
  {
    "objectID": "chapters/15a_Meta_Analysis.html#systematic-reviews",
    "href": "chapters/15a_Meta_Analysis.html#systematic-reviews",
    "title": "20  Systematic Review and Meta-analysis",
    "section": "",
    "text": "Key characteristics:\n\nProtocol-Driven: It starts with a written protocol defining the research question, search strategy, inclusion/exclusion criteria, and risk of bias assessment.\nReproducible: Another researcher should be able to follow your protocol and find the same studies.\nComprehensive: Aims to find all relevant studies, typically searching multiple databases (PubMed, Embase, Cochrane, etc.).\nObjective: Inclusion decisions are based on pre-defined criteria, often involving two independent reviewers to reduce subjectivity.\n\n\n\nSystematic Review Steps:\n\n1. Write Protocol:\nDefine the study question (often using PICOS: Population, Intervention, Comparison, Outcome, Study design).\n\n\n2. Search Literature:\nExecute comprehensive search queries in databases.\n\n\n3. Screening:\nReview titles, abstracts, and full texts against eligibility criteria.\n\n\n4. Abstract Data:\nExtract relevant data (estimates, sample sizes, etc.) from included studies.\n\n\n5. Assess Risk of Bias:\nEvaluate the quality of individual studies (e.g., confounding, blinding, attrition).\n\n\n6. Summarize Evidence:\nQualitatively describe findings; if data allows, proceed to quantitative synthesis (meta-analysis).\n\n\n7. Reporting:\nUse the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) checklist and flow diagram.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Systematic Review and Meta-analysis</span>"
    ]
  },
  {
    "objectID": "chapters/15a_Meta_Analysis.html#meta-analyses",
    "href": "chapters/15a_Meta_Analysis.html#meta-analyses",
    "title": "20  Systematic Review and Meta-analysis",
    "section": "Meta-Analyses",
    "text": "Meta-Analyses\nA meta-analysis is a statistical technique often used within a systematic review to quantitatively combine results from multiple independent studies into a single pooled estimate.\nWhy conduct one?\n\nIncrease Power/Precision: Pooling sample sizes leads to tighter confidence intervals and greater ability to detect effects.\nSynthesize Evidence: It provides a summary answer when individual studies might be conflicting or too small.",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Systematic Review and Meta-analysis</span>"
    ]
  },
  {
    "objectID": "chapters/15a_Meta_Analysis.html#meta-analysis-steps",
    "href": "chapters/15a_Meta_Analysis.html#meta-analysis-steps",
    "title": "20  Systematic Review and Meta-analysis",
    "section": "Meta-Analysis Steps",
    "text": "Meta-Analysis Steps\n\n1. Write systematic review protocol\n\n\n2. Search the literature\n\n\n3. Review titles, abstracts, and full texts\n\n\n4. Abstract data from included studies\n\n\n5. Assess risk of bias\n\n\n6. Assess heterogeneity of measures of association\nExamine forest plot for heterogeneity:\n\neach study is one row in the plot\nthis plot shows the combined effect estimate, but this is estimated after this initial assessment\nthe dashed line corresponds to the pooled estimate\nthe solid line corresponds to the null\nmost effect estimates are to the left of the null and have a similar value, suggesting litte heterogeneity\n\n\n\nindividual studies’ MOAs may differ for a number of reasons: different population characteristics (age, sex, race); year(s) of study; location; participants’ symptoms / clinical characteristics; different variables treated as confounders; study design; sample sizes; statistical analyses\n\nTest for heterogeneity using a Q-statistic (type of chi-square test)\nIt is a weighted sum of squared differences between individual study effects (\\(MoA_i\\)) and the summary effect (\\(MoA_s\\)).\n\nNull (\\(H_0\\)): no heterogeneity among original studies\nFormula: \\(Q = \\sum w_i (MoA_i - MoA_s)^2\\)\n\nInterpretation:\nA significant p-value (typically p &lt; 0.20 or 0.10, not 0.05) indicates significant heterogeneity.\nIf \\(p &lt; 0.2\\), reject \\(H_0\\).\nTest for heterogeneity using \\(I^2\\) Statistic:\n\\(I^2\\) Statistic: Describes the percentage of variation across studies due to heterogeneity rather than chance\nFormula: \\(I^2 = \\frac{Q - df}{Q} \\times 100\\)\n\n(where \\(df = k-1\\) studies)\n\nInterpretation: \\(I^2 &gt; 50\\%\\) suggests substantial heterogeneity\n\n\n7. Obtain pooled measure of association and Conduct any subgroup analyses\nYou calculate a weighted average: \\(MoA_s = \\frac{\\sum (w_i \\times MoA_i)}{\\sum w_i}\\)\nThe definition of the weight (\\(w_i\\)) depends on your model choice:\nFixed Effects Model:\n\nAssumption: All studies estimate a common, underlying effect. Differences are due only to sampling error\nInference: Applies only to the specific studies in the meta-analysis\nUse when: There is little evidence of heterogeneity (\\(I^2 &lt; 50\\%\\))\nWeights: Typically inverse variance (\\(w_i = 1/v_i\\))\n\nRandom Effects Model:\n\nAssumption: The true effect size varies across studies. Studies are a random sample of a larger population of studies\nInference: Generalizes to a hypothetical population of similar studies\nUse when: There is significant heterogeneity (\\(I^2 &gt; 50\\%\\)) or you wish to generalize broadly\nWeights: Inverse variance plus between-study variance (\\(w_i^* = 1/(v_i + \\tau^2)\\))\n\nNote: This results in wider confidence intervals and more conservative estimates than fixed effects\n\n\n\n\n8. Assess publication bias\nVisual Check: Look at a Funnel Plot\n\nX-axis: Treatment effect (e.g., Log OR)\nY-axis: Precision (e.g., Standard Error or Sample Size)\nInterpretation: In the absence of bias, it should look like a symmetric inverted funnel\n“File Drawer Problem”\n\nAsymmetry, specifically a “bite” missing from the bottom corner (small, non-significant studies), suggests publication bias—meaning negative/null studies were likely never published",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Systematic Review and Meta-analysis</span>"
    ]
  },
  {
    "objectID": "chapters/15a_Meta_Analysis.html#key-take-aways",
    "href": "chapters/15a_Meta_Analysis.html#key-take-aways",
    "title": "20  Systematic Review and Meta-analysis",
    "section": "Key Take-Aways:",
    "text": "Key Take-Aways:\nForest Plots: Be able to identify individual study weights (box size), point estimates, confidence intervals, and the pooled estimate (diamond). Know that crossing the null line (1.0 for ratios, 0 for differences) means non-significance\nModel Selection Logic:\n\nHigh Heterogeneity (\\(I^2 &gt; 50\\%\\), significant Q): Use Random Effects (or do not pool)\nLow Heterogeneity: Fixed Effects is acceptable\n\nWeighting: Understand that larger studies (smaller variance) get more weight. Random effects models produce more equal weights between small and large studies compared to fixed effects\nSubgroup Analysis: Understand this is used to explore sources of heterogeneity (e.g., blinded vs. unblinded trials).\nCaution: Do not test for statistical significance between subgroups; only compare magnitudes",
    "crumbs": [
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Systematic Review and Meta-analysis</span>"
    ]
  },
  {
    "objectID": "chapters/15b_Population_Intervention_Effects.html",
    "href": "chapters/15b_Population_Intervention_Effects.html",
    "title": "21  Population_Intervention_Effects",
    "section": "",
    "text": "The Motivation (Why do we need this?)\nPopulation intervention effects are causal effects that compare the observed population risk (or outcome) to the risk under a specific, realistic counterfactual intervention scenario\nPopulation intervention effects are a critical tool because they move us away from theoretical “all-or-nothing” comparisons toward policy-relevant questions.\nTraditional measures like the Risk Difference (RD) usually compare a scenario where 100% of the population is treated (\\(R_e\\)) versus 0% treated (\\(R_u\\)).\nThe Problem: In the real world, it is rarely feasible to treat everyone (100%) or no one (0%). Therefore, \\(R_e\\) and \\(R_u\\) are often unrealistic scenarios.\nThe Solution: We need a parameter that lets us define customized, realistic scenarios (e.g., “What if we increased vaccination from the current 40% to 80%?”)",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Population_Intervention_Effects</span>"
    ]
  },
  {
    "objectID": "chapters/15b_Population_Intervention_Effects.html#comparison-with-other-parameters",
    "href": "chapters/15b_Population_Intervention_Effects.html#comparison-with-other-parameters",
    "title": "21  Population_Intervention_Effects",
    "section": "Comparison with Other Parameters",
    "text": "Comparison with Other Parameters\n\n\n\n\n\n\n\n\n\nParameter\nFormula\nComparison\nRealism & Usage\n\n\n\n\nRisk Difference (RD)\n\\(R_e - R_u\\)\n100% Exposed (\\(R_e\\)) vs. 0% Exposed (\\(R_u\\))\n[cite_start]Least Realistic: It assumes perfect implementation (100% coverage), which is rarely achievable[cite: 2096, 2136].\n\n\nPop. Attributable Fraction (PAF)\n\\((R_t - R_u) / R_t\\)\nObserved (\\(R_t\\)) vs. 0% Exposed (\\(R_u\\))\n[cite_start]Intermediate: More realistic than RD because it uses the current exposure level (\\(R_t\\)), but still compares against an unrealistic 0% exposed counterfactual[cite: 1991, 2141].\n\n\nPop. Intervention Effect\n\\(R_I - R_0\\)\nIdeal Target (\\(R_I\\)) vs. Observed (\\(R_0\\))\nMost Realistic: Directly answers the policy question: “How much impact would we see if we reached our target coverage?” (e.g., 40% vs 80%) [cite_start][cite: 2064, 2143].",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Population_Intervention_Effects</span>"
    ]
  },
  {
    "objectID": "chapters/15b_Population_Intervention_Effects.html#calculation-method-g-computation",
    "href": "chapters/15b_Population_Intervention_Effects.html#calculation-method-g-computation",
    "title": "21  Population_Intervention_Effects",
    "section": "Calculation Method: G-Computation",
    "text": "Calculation Method: G-Computation\nWe use G-computation to estimate these effects. There are 5 key steps:\n\nModel:\n\nEstimate the association between the exposure and outcome using a regression model, adjusting for confounders\n\nPredict Counterfactuals:\n\nUse the model coefficients to predict outcomes for every individual in the dataset under two specific scenarios:\n\nCounterfactual Scenario 1 (\\(R_I\\)): Set exposure to the “Ideal” level (e.g., everyone who meets specific criteria gets treated)\nCounterfactual Scenario 2 (\\(R_0\\)): Set exposure to the “Observed” level (often just the original data)\n\n\nEstimate Population Risk:\n\nCalculate the average of these predicted probabilities/outcomes for the entire population under Scenario 1 and Scenario 2\n\nCalculate Effect:\n\nTake the difference (or ratio) of the two population averages (\\(R_I - R_0\\))\n\nInference:\n\nUse bootstrapping to obtain 95% confidence intervals (because standard errors are difficult to calculate analytically here)",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Population_Intervention_Effects</span>"
    ]
  },
  {
    "objectID": "chapters/15b_Population_Intervention_Effects.html#key-take-aways",
    "href": "chapters/15b_Population_Intervention_Effects.html#key-take-aways",
    "title": "21  Population_Intervention_Effects",
    "section": "Key Take-aways",
    "text": "Key Take-aways\nDefinition & Interpretation: Be able to define a population intervention effect. It allows us to define customized counterfactual scenarios tailored to a specific research question.\nExam Tip: Be ready to interpret a result.\n“The result (\\(R_I - R_0\\)) estimates the reduction in disease incidence if the program had reached its target coverage (80%) compared to the observed coverage (40%)”\nWhy choose it? Be prepared to explain why you would use this over RD or PAF. The keywords are “realistic” and “policy-relevant.” It avoids unrealistic assumptions like 100% compliance\nExamples: Recognize scenarios where this applies:\n\nExample: HIV PrEP campaigns reaching 85% of targets vs. current levels\nExample: Comparing neighborhoods with high vs. low density of alcohol outlets\n\nMethodology: Remember that G-computation is the tool used for estimation and that bootstrapping is required for confidence intervals.",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Population_Intervention_Effects</span>"
    ]
  },
  {
    "objectID": "chapters/15c_Spillover_Effects.html",
    "href": "chapters/15c_Spillover_Effects.html",
    "title": "22  Spillover Effects",
    "section": "",
    "text": "Four Key Spillover Parameters & Calculations\nIn standard epidemiology, we typically assume that one individual’s outcome is independent of another’s (Stable Unit Treatment Value Assumption, or SUTVA). However, in infectious diseases or social network behaviors, this assumption often fails\nA spillover effect occurs when an intervention affects individuals who were not targeted by the intervention but are connected to recipients via social, geographic, or other networks\nSynonyms to recognize: Herd immunity, indirect effects, externalities, contagion effects, diffusion\nYou must understand the implications of ignoring spillovers.\nIf an intervention spills over to the control group (often called “contamination” in cluster-randomized trials), the control group’s outcomes become more similar to the intervention group.\nThis leads to bias towards the null (underestimating the true effect)\n\\(Y\\): Outcome\n\\(X\\): Cluster treatment assignment (\\(1 =\\) treated cluster, \\(0 =\\) control cluster)\n\\(T\\): Individual treatment assignment (\\(1 =\\) treated person, \\(0 =\\) untreated person)",
    "crumbs": [
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Spillover Effects</span>"
    ]
  },
  {
    "objectID": "chapters/15c_Spillover_Effects.html#four-key-spillover-parameters-calculations",
    "href": "chapters/15c_Spillover_Effects.html#four-key-spillover-parameters-calculations",
    "title": "22  Spillover Effects",
    "section": "",
    "text": "Within-Cluster Spillover Effect\nThis is the most common parameter in cluster-randomized trials (CRTs). It measures the effect on untreated people inside a treated cluster compared to people in a control cluster.\nScenario: Comparing untreated individuals in a treated village (who benefit indirectly) vs. untreated individuals in a control village\nCalculation:\n\\[E[Y | X=1, T=0] - E[Y | X=0, T=0]\\]\nCritical Assumption: “Partial Interference”\n\nspillovers occur within clusters but not between clusters\n\n\n\nSpillover Conditional on Distance\nThis parameter is used when effects extend beyond cluster boundaries (e.g., mosquitoes flying from a treated village to a nearby untreated one)\nScenario: Comparing untreated individuals living within a specific distance (\\(d\\)) of a treated cluster vs. untreated individuals within distance (\\(d\\)) of a control cluster\nCalculation:\n\\[E[Y | X=1, T=0, D=d] - E[Y | X=0, T=0, D=d]\\]\n\n\nSpillover Conditional on Treatment Density\nThis looks at how the concentration of treatment around a person affects them.\nScenario: Comparing outcomes for untreated individuals in an area with high treatment coverage (e.g., 90%) vs. untreated individuals in an area with lower or zero coverage\nCalculation:\n\\[E[Y | T=0, P=p+\\delta] - E[Y | T=0, P=p]\\]\nWhere \\(P\\) is treatment density (proportion treated) and \\(\\delta\\) is the change in density (e.g., comparing 0% vs 50%)\n\n\nNetwork Spillover Effect\nThis applies to social networks (e.g., friends of people in a smoking cessation program)\nNotation Change: Here, \\(T\\) refers to the connection status (connected to treated vs. connected to control), and \\(C=1\\) indicates the person is an “alter” (a connected friend) rather than the primary participant\nCalculation:\n\\[E[Y | T=1, C=1] - E[Y | T=0, C=1]\\]\nComparing an alter connected to a treated ego vs. an alter connected to a control ego.",
    "crumbs": [
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Spillover Effects</span>"
    ]
  },
  {
    "objectID": "chapters/15c_Spillover_Effects.html#key-take-aways",
    "href": "chapters/15c_Spillover_Effects.html#key-take-aways",
    "title": "22  Spillover Effects",
    "section": "Key Take-aways",
    "text": "Key Take-aways\nYou should know which designs allow us to estimate these effects validly.\nDouble-Randomized Trials (Two-Stage Randomization): This is the gold standard for estimating within-cluster spillovers\n\nStage 1: Randomize clusters to Treatment or Control\nStage 2: Randomize individuals within the treatment clusters to receive the intervention or not\nWhy? It balances confounders between treated and untreated people within the same cluster, allowing for valid estimation of direct and spillover effects\n\nDefine the Counterfactuals: Be able to translate a word problem (e.g., “untreated neighbors of treated households”) into the \\(E[Y|...]\\) notation.\nIdentify Bias: If a problem states that “control villages were close to intervention villages,” recognize this as contamination leading to bias towards the null\nSelect the Design: If asked how to rigorously measure the indirect effect of a vaccine within a village, identify the Double-Randomized Trial as the ideal design\nInterpret the Result: Explain that spillover effects capture the “real-world” impact and cost-effectiveness better than simple direct effects because they account for population-level transmission dynamics",
    "crumbs": [
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Spillover Effects</span>"
    ]
  },
  {
    "objectID": "chapters/15d_Replication_Transparency_Reproducibility.html",
    "href": "chapters/15d_Replication_Transparency_Reproducibility.html",
    "title": "23  Replication, Transparency, and Reproducibility",
    "section": "",
    "text": "Main threats to reproducibility:\nThe field is currently facing a “reproducibility crisis,” where many published findings across disciplines (psychology, economics, basic science) cannot be replicated by other researchers.",
    "crumbs": [
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Replication, Transparency, and Reproducibility</span>"
    ]
  },
  {
    "objectID": "chapters/15d_Replication_Transparency_Reproducibility.html#main-threats-to-reproducibility",
    "href": "chapters/15d_Replication_Transparency_Reproducibility.html#main-threats-to-reproducibility",
    "title": "23  Replication, Transparency, and Reproducibility",
    "section": "",
    "text": "Failure to Control for Bias:\nSystematic errors in design or analysis (e.g., unmeasured confounding in observational studies, improper randomization or lack of blinding in trials) lead to non-reproducible results\n\n\nLow Statistical Power:\nSmall sample sizes increase the risk of Type II errors (failing to detect a true effect). Published findings from underpowered studies are often incorrect and difficult to reproduce\n\n\nPoor Quality Control:\nErrors during data collection (e.g., poor survey design) or analysis (e.g., coding errors) contribute to bias and misclassification\n\n\nP-Hacking:\nThis occurs when investigators repeatedly adjust their statistical models after seeing the data to obtain a desirable p-value (e.g., &lt; 0.05)\n\nKey: The resulting p-value is confounded by the number of tests run and does not represent the true probability of a Type I error\n\n\n\nPublication Bias:\nJournals prefer publishing “positive” or statistically significant findings. Null or “negative” findings are often not published (the “file drawer problem”), making the published literature a biased representation of reality\n\n\nConfirmation Bias:\nResearchers naturally look for patterns that confirm their expectations. They are more likely to scrutinize results that contradict their expectations while letting errors in “expected” results go unnoticed",
    "crumbs": [
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Replication, Transparency, and Reproducibility</span>"
    ]
  },
  {
    "objectID": "chapters/15d_Replication_Transparency_Reproducibility.html#positive-predictive-value",
    "href": "chapters/15d_Replication_Transparency_Reproducibility.html#positive-predictive-value",
    "title": "23  Replication, Transparency, and Reproducibility",
    "section": "Positive Predictive Value",
    "text": "Positive Predictive Value\nThe probability that a research finding is actually true depends on three factors\n\n1. Pre-study probability (\\(R\\)):\nThe ratio of “true relationships” to “no relationships” in the field (\\(R/(R+1)\\))\n\n\n2. Statistical Power:\n(\\(1 - \\beta\\)): The probability of finding a true relationship\n\n\n3. Level of Statistical Significance ( \\(\\alpha\\) ):\nThe probability of claiming a relationship when none exists (Type I error)\n\n\nPositive Predictive Value Formula:\n\\[PPV = \\frac{(1 - \\beta)R}{R - \\beta R + \\alpha}\\]\n\nSmall sample size (low power): Lower PPV (less likely to be true)\nSmall effect sizes: Lower PPV\nGreater flexibility in analysis (bias): Lower PPV\n“Hotter” fields (more teams testing): Lower PPV for any single isolated finding",
    "crumbs": [
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Replication, Transparency, and Reproducibility</span>"
    ]
  },
  {
    "objectID": "chapters/15d_Replication_Transparency_Reproducibility.html#key-take-aways",
    "href": "chapters/15d_Replication_Transparency_Reproducibility.html#key-take-aways",
    "title": "23  Replication, Transparency, and Reproducibility",
    "section": "Key Take-aways:",
    "text": "Key Take-aways:\nMap Threats to Solutions: Be able to match a specific problem (e.g., “p-hacking”) to its specific solution (e.g., “pre-analysis plan”).\nDefine “Spillover” correctly: Don’t confuse it with reproducibility. (Note: Spillover is a separate topic in this module, referring to effects on non-targeted individuals ).\nUnderstand the “Why”: Why is a registered report better than standard publication? (Answer: It removes the incentive to produce only positive results, thus reducing publication bias )\nIoannidis’ Main Argument:\nUnderstand why he argues most findings are false:\n\nIt is a mathematical consequence of testing many hypotheses with:\n\nlow prior probability (low \\(R\\)),\nlow power, and\nhigh bias",
    "crumbs": [
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Replication, Transparency, and Reproducibility</span>"
    ]
  }
]